{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import all the things!\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.cross_validation import KFold\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.grid_search import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = pd.read_csv('../titanic.csv')\n",
    "y = X.pop('Survived')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Driz/anaconda2/lib/python2.7/site-packages/numpy/lib/function_base.py:3834: RuntimeWarning: Invalid value encountered in percentile\n",
      "  RuntimeWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>714.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>445.000000</td>\n",
       "      <td>446.000000</td>\n",
       "      <td>2.308642</td>\n",
       "      <td>29.699118</td>\n",
       "      <td>0.523008</td>\n",
       "      <td>0.381594</td>\n",
       "      <td>32.204208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>257.353842</td>\n",
       "      <td>257.353842</td>\n",
       "      <td>0.836071</td>\n",
       "      <td>14.526497</td>\n",
       "      <td>1.102743</td>\n",
       "      <td>0.806057</td>\n",
       "      <td>49.693429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>222.500000</td>\n",
       "      <td>223.500000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.910400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>445.000000</td>\n",
       "      <td>446.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.454200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>667.500000</td>\n",
       "      <td>668.500000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>890.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>512.329200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            index  PassengerId      Pclass         Age       SibSp  \\\n",
       "count  891.000000   891.000000  891.000000  714.000000  891.000000   \n",
       "mean   445.000000   446.000000    2.308642   29.699118    0.523008   \n",
       "std    257.353842   257.353842    0.836071   14.526497    1.102743   \n",
       "min      0.000000     1.000000    1.000000    0.420000    0.000000   \n",
       "25%    222.500000   223.500000    2.000000         NaN    0.000000   \n",
       "50%    445.000000   446.000000    3.000000         NaN    0.000000   \n",
       "75%    667.500000   668.500000    3.000000         NaN    1.000000   \n",
       "max    890.000000   891.000000    3.000000   80.000000    8.000000   \n",
       "\n",
       "            Parch        Fare  \n",
       "count  891.000000  891.000000  \n",
       "mean     0.381594   32.204208  \n",
       "std      0.806057   49.693429  \n",
       "min      0.000000    0.000000  \n",
       "25%      0.000000    7.910400  \n",
       "50%      0.000000   14.454200  \n",
       "75%      0.000000   31.000000  \n",
       "max      6.000000  512.329200  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.describe()\n",
    "# age has missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>445.000000</td>\n",
       "      <td>446.000000</td>\n",
       "      <td>2.308642</td>\n",
       "      <td>29.699118</td>\n",
       "      <td>0.523008</td>\n",
       "      <td>0.381594</td>\n",
       "      <td>32.204208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>257.353842</td>\n",
       "      <td>257.353842</td>\n",
       "      <td>0.836071</td>\n",
       "      <td>13.002015</td>\n",
       "      <td>1.102743</td>\n",
       "      <td>0.806057</td>\n",
       "      <td>49.693429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>222.500000</td>\n",
       "      <td>223.500000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.910400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>445.000000</td>\n",
       "      <td>446.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>29.699118</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.454200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>667.500000</td>\n",
       "      <td>668.500000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>890.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>512.329200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            index  PassengerId      Pclass         Age       SibSp  \\\n",
       "count  891.000000   891.000000  891.000000  891.000000  891.000000   \n",
       "mean   445.000000   446.000000    2.308642   29.699118    0.523008   \n",
       "std    257.353842   257.353842    0.836071   13.002015    1.102743   \n",
       "min      0.000000     1.000000    1.000000    0.420000    0.000000   \n",
       "25%    222.500000   223.500000    2.000000   22.000000    0.000000   \n",
       "50%    445.000000   446.000000    3.000000   29.699118    0.000000   \n",
       "75%    667.500000   668.500000    3.000000   35.000000    1.000000   \n",
       "max    890.000000   891.000000    3.000000   80.000000    8.000000   \n",
       "\n",
       "            Parch        Fare  \n",
       "count  891.000000  891.000000  \n",
       "mean     0.381594   32.204208  \n",
       "std      0.806057   49.693429  \n",
       "min      0.000000    0.000000  \n",
       "25%      0.000000    7.910400  \n",
       "50%      0.000000   14.454200  \n",
       "75%      0.000000   31.000000  \n",
       "max      6.000000  512.329200  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# impute age with mean\n",
    "X['Age'].fillna(X.Age.mean(), inplace=True)\n",
    "\n",
    "# confirm\n",
    "X.describe()\n",
    "\n",
    "# ignoring categorical variables for right now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index  PassengerId  Pclass   Age  SibSp  Parch     Fare\n",
       "0      0            1       3  22.0      1      0   7.2500\n",
       "1      1            2       1  38.0      1      0  71.2833\n",
       "2      2            3       3  26.0      0      0   7.9250\n",
       "3      3            4       1  35.0      1      0  53.1000\n",
       "4      4            5       3  35.0      0      0   8.0500"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# return just numeric variables ignoring 'object' datatypes\n",
    "numeric_variables = list(X.dtypes[X.dtypes != 'object'].index)\n",
    "X[numeric_variables].head()\n",
    "# passenger id seems ignorable "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LogisticRegression()\n",
    "model.fit(X[numeric_variables], y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.70258136924803594"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# not shabby for a quick model to get going, but I think I can get a better score\n",
    "model.score(X[numeric_variables], y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method LogisticRegression.predict_proba of LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# do predictions to get to confusion matrix\n",
    "# not sure what I was going with this\n",
    "model.predict_proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# function to show descriptive stats on categorical variables\n",
    "def describe_categorical(X):\n",
    "    from IPython.display import display, HTML\n",
    "    display(HTML(X[X.columns[X.dtypes == 'object']].describe().to_html()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>891</td>\n",
       "      <td>891</td>\n",
       "      <td>891</td>\n",
       "      <td>204</td>\n",
       "      <td>889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>891</td>\n",
       "      <td>2</td>\n",
       "      <td>681</td>\n",
       "      <td>147</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>Graham, Mr. George Edward</td>\n",
       "      <td>male</td>\n",
       "      <td>CA. 2343</td>\n",
       "      <td>C23 C25 C27</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>1</td>\n",
       "      <td>577</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>644</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "describe_categorical(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# drop variables I dont want in this\n",
    "X.drop(['Name', 'Ticket', 'PassengerId'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# change cabin variable to be first letter\n",
    "def clean_cabin(x):\n",
    "    try:\n",
    "        return x[0]\n",
    "    except TypeError:\n",
    "        return 'None'\n",
    "    \n",
    "X['Cabin'] = X.Cabin.apply(clean_cabin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    None\n",
       "1       C\n",
       "2    None\n",
       "3       C\n",
       "4    None\n",
       "Name: Cabin, dtype: object"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# if data is missing returns none\n",
    "X.Cabin.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "categorical_variables = ['Sex', 'Cabin', 'Embarked']\n",
    "\n",
    "for variable in categorical_variables:\n",
    "    X[variable].fillna('Missing', inplace=True)\n",
    "    dummies = pd.get_dummies(X[variable], prefix=variable)\n",
    "    X = pd.concat([X, dummies], axis=1)\n",
    "    X.drop([variable], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Sex_female</th>\n",
       "      <th>Sex_male</th>\n",
       "      <th>Cabin_A</th>\n",
       "      <th>Cabin_B</th>\n",
       "      <th>Cabin_C</th>\n",
       "      <th>Cabin_D</th>\n",
       "      <th>Cabin_E</th>\n",
       "      <th>Cabin_F</th>\n",
       "      <th>Cabin_G</th>\n",
       "      <th>Cabin_None</th>\n",
       "      <th>Cabin_T</th>\n",
       "      <th>Embarked_C</th>\n",
       "      <th>Embarked_Missing</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Embarked_S</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>886</td>\n",
       "      <td>2</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>887</td>\n",
       "      <td>1</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>888</td>\n",
       "      <td>3</td>\n",
       "      <td>29.699118</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>23.4500</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>889</td>\n",
       "      <td>1</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>890</td>\n",
       "      <td>3</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.7500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# to make sure there is no compression in the columns\n",
    "def printall(X, max_rows=10):\n",
    "    from IPython.display import display, HTML\n",
    "    display(HTML(X.to_html(max_rows=max_rows)))\n",
    "    \n",
    "printall(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.81032547699214363"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# that is a pretty good score, but it is using a lot of the data--overfit?\n",
    "model = LogisticRegression()\n",
    "model.fit (X, y)\n",
    "model.score(X, y)\n",
    "# print \"C-stat\", roc_auc_score(y, model.predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Sex_female</th>\n",
       "      <th>Sex_male</th>\n",
       "      <th>Cabin_A</th>\n",
       "      <th>Cabin_B</th>\n",
       "      <th>...</th>\n",
       "      <th>Cabin_D</th>\n",
       "      <th>Cabin_E</th>\n",
       "      <th>Cabin_F</th>\n",
       "      <th>Cabin_G</th>\n",
       "      <th>Cabin_None</th>\n",
       "      <th>Cabin_T</th>\n",
       "      <th>Embarked_C</th>\n",
       "      <th>Embarked_Missing</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Embarked_S</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   index  Pclass   Age  SibSp  Parch     Fare  Sex_female  Sex_male  Cabin_A  \\\n",
       "0      0       3  22.0      1      0   7.2500         0.0       1.0      0.0   \n",
       "1      1       1  38.0      1      0  71.2833         1.0       0.0      0.0   \n",
       "2      2       3  26.0      0      0   7.9250         1.0       0.0      0.0   \n",
       "3      3       1  35.0      1      0  53.1000         1.0       0.0      0.0   \n",
       "4      4       3  35.0      0      0   8.0500         0.0       1.0      0.0   \n",
       "\n",
       "   Cabin_B     ...      Cabin_D  Cabin_E  Cabin_F  Cabin_G  Cabin_None  \\\n",
       "0      0.0     ...          0.0      0.0      0.0      0.0         1.0   \n",
       "1      0.0     ...          0.0      0.0      0.0      0.0         0.0   \n",
       "2      0.0     ...          0.0      0.0      0.0      0.0         1.0   \n",
       "3      0.0     ...          0.0      0.0      0.0      0.0         0.0   \n",
       "4      0.0     ...          0.0      0.0      0.0      0.0         1.0   \n",
       "\n",
       "   Cabin_T  Embarked_C  Embarked_Missing  Embarked_Q  Embarked_S  \n",
       "0      0.0         0.0               0.0         0.0         1.0  \n",
       "1      0.0         1.0               0.0         0.0         0.0  \n",
       "2      0.0         0.0               0.0         0.0         1.0  \n",
       "3      0.0         0.0               0.0         0.0         1.0  \n",
       "4      0.0         0.0               0.0         0.0         1.0  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# just checking in \n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0\n",
       "1    1\n",
       "2    1\n",
       "3    1\n",
       "4    0\n",
       "Name: Survived, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# just checking in\n",
    "y.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "TEST TRAIN SPLIT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((668, 21), (223, 21))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lets set up a test and train set of data\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y)\n",
    "\n",
    "x_train.shape, x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pclass=1</th>\n",
       "      <th>pclass=2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pclass=1  pclass=2\n",
       "0       0.0       0.0\n",
       "1       1.0       0.0\n",
       "2       0.0       0.0\n",
       "3       1.0       0.0\n",
       "4       0.0       0.0"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# need to pluck only two of the three choices\n",
    "pclass_dummies = pd.get_dummies(X['Pclass'])\n",
    "pclass_dummies = pclass_dummies[[1, 2]]\n",
    "pclass_dummies.columns = ['pclass=1', 'pclass=2']\n",
    "pclass_dummies.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Embarked_Missing</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Embarked_S</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Embarked_Missing  Embarked_Q  Embarked_S\n",
       "0               0.0         0.0         1.0\n",
       "1               0.0         0.0         0.0\n",
       "2               0.0         0.0         1.0\n",
       "3               0.0         0.0         1.0\n",
       "4               0.0         0.0         1.0"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# need to pluck only two of the three choices\n",
    "embarked_dummies = (X[['Embarked_Missing', 'Embarked_Q', 'Embarked_S']])\n",
    "embarked_dummies.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pclass=1</th>\n",
       "      <th>pclass=2</th>\n",
       "      <th>Sex_male</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Embarked_Missing</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Embarked_S</th>\n",
       "      <th>Child</th>\n",
       "      <th>Old Person</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pclass=1  pclass=2  Sex_male   Age  SibSp  Parch  Embarked_Missing  \\\n",
       "0       0.0       0.0       1.0  22.0      1      0               0.0   \n",
       "1       1.0       0.0       0.0  38.0      1      0               0.0   \n",
       "2       0.0       0.0       0.0  26.0      0      0               0.0   \n",
       "3       1.0       0.0       0.0  35.0      1      0               0.0   \n",
       "4       0.0       0.0       1.0  35.0      0      0               0.0   \n",
       "\n",
       "   Embarked_Q  Embarked_S  Child  Old Person  \n",
       "0         0.0         1.0      0           0  \n",
       "1         0.0         0.0      0           0  \n",
       "2         0.0         1.0      0           0  \n",
       "3         0.0         1.0      0           0  \n",
       "4         0.0         1.0      0           0  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analytic_df = pclass_dummies.join(X['Sex_male'])\n",
    "analytic_df = analytic_df.join(X[['Age', 'SibSp', 'Parch']])\n",
    "analytic_df = analytic_df.join(embarked_dummies)\n",
    "analytic_df['Child'] = analytic_df['Age'].apply(lambda x: 1 if x < 12 else 0)\n",
    "analytic_df['Old Person'] = analytic_df['Age'].apply(lambda x: 1 if x > 50 else 0)\n",
    "analytic_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(891, 11)\n",
      "(891, 11)\n"
     ]
    }
   ],
   "source": [
    "# shouldnt have any nulls cause I filled them earlier\n",
    "print analytic_df.shape\n",
    "analytic_df.dropna(inplace=True)\n",
    "print analytic_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.81032547699214363"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analytic_log = LogisticRegression()\n",
    "analytic_log.fit(analytic_df, y)\n",
    "analytic_log.score(analytic_df, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SelectKBest(k='all', score_func=<function f_classif at 0x117618668>)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lets do a kbest on train data\n",
    "kbest = SelectKBest(k='all')\n",
    "kbest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.,  1., ...,  1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  1.,  0.,  0.],\n",
       "       ..., \n",
       "       [ 0.,  0.,  0., ...,  1.,  0.,  0.],\n",
       "       [ 1.,  0.,  1., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  1., ...,  0.,  0.,  0.]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_kbest_all = kbest.fit_transform(analytic_df, y)\n",
    "results_kbest_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  7.91364033e+01,   7.81480472e+00,   3.72405724e+02,\n",
       "         4.35351609e+00,   1.11057220e+00,   5.96346384e+00,\n",
       "         3.22216280e+00,   1.18463440e-02,   2.20754686e+01,\n",
       "         1.13176268e+01,   4.67733759e-01])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kbest.scores_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "logistic_regression_factory = LogisticRegression()\n",
    "rfe_factory = RFE(estimator=logistic_regression_factory, step=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.,  1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.],\n",
       "       ..., \n",
       "       [ 0.,  0.,  0.,  0.,  0.],\n",
       "       [ 1.,  0.,  1.,  0.,  0.],\n",
       "       [ 0.,  0.,  1.,  0.,  0.]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_of_rfe = rfe_factory.fit_transform(analytic_df, y)\n",
    "results_of_rfe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Shows three model scores. KBest, rfe, and logistic regression on the dataframe. The models were run on the full dataset and there is probably some overfitting. Can retest models on train/test data. Not sure whether to further pursue kbest and rfe for this dataset or just switch over to gridsearch..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.81032547699214363"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_kbest_all_columns = LogisticRegression()\n",
    "model_kbest_all_columns.fit(results_kbest_all, y)\n",
    "model_kbest_all_columns.score(results_kbest_all, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.78900112233445563"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_for_rfe_columns = LogisticRegression()\n",
    "model_for_rfe_columns.fit(results_of_rfe, y)\n",
    "model_for_rfe_columns.score(results_of_rfe, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.81032547699214363"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_df = LogisticRegression()\n",
    "full_df.fit(analytic_df.as_matrix(), y)\n",
    "full_df.score(analytic_df.as_matrix(), y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like my kbest and entire df have same results. Should go back and restrict k='all'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SelectKBest(k=4, score_func=<function f_classif at 0x117618668>)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lets redo a kbest on train data with restricted columns\n",
    "kbest = SelectKBest(k=4)\n",
    "kbest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  1.,  1.,  0.],\n",
       "       [ 1.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  1.,  0.],\n",
       "       ..., \n",
       "       [ 0.,  0.,  1.,  0.],\n",
       "       [ 1.,  1.,  0.,  0.],\n",
       "       [ 0.,  1.,  0.,  0.]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_of_kbest4 = kbest.fit_transform(analytic_df, y)\n",
    "results_of_kbest4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  7.91364033e+01,   7.81480472e+00,   3.72405724e+02,\n",
       "         4.35351609e+00,   1.11057220e+00,   5.96346384e+00,\n",
       "         3.22216280e+00,   1.18463440e-02,   2.20754686e+01,\n",
       "         1.13176268e+01,   4.67733759e-01])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kbest.scores_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.79012345679012341"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# showing a lower score with less variables\n",
    "model_for_kbest4_columns = LogisticRegression()\n",
    "model_for_kbest4_columns.fit(results_of_kbest4, y)\n",
    "model_for_kbest4_columns.score(results_of_kbest4, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, moving back to logistic regression for now. Then will run it through a grid search. Going to do these models on train data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((668, 21), (668,))"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pclass=1</th>\n",
       "      <th>pclass=2</th>\n",
       "      <th>Sex_male</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Embarked_Missing</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Embarked_S</th>\n",
       "      <th>Child</th>\n",
       "      <th>Old Person</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pclass=1  pclass=2  Sex_male   Age  SibSp  Parch  Embarked_Missing  \\\n",
       "0       0.0       0.0       1.0  22.0      1      0               0.0   \n",
       "1       1.0       0.0       0.0  38.0      1      0               0.0   \n",
       "2       0.0       0.0       0.0  26.0      0      0               0.0   \n",
       "3       1.0       0.0       0.0  35.0      1      0               0.0   \n",
       "4       0.0       0.0       1.0  35.0      0      0               0.0   \n",
       "\n",
       "   Embarked_Q  Embarked_S  Child  Old Person  \n",
       "0         0.0         1.0      0           0  \n",
       "1         0.0         0.0      0           0  \n",
       "2         0.0         1.0      0           0  \n",
       "3         0.0         1.0      0           0  \n",
       "4         0.0         1.0      0           0  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analytic_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Sex_female</th>\n",
       "      <th>Sex_male</th>\n",
       "      <th>Cabin_A</th>\n",
       "      <th>Cabin_B</th>\n",
       "      <th>...</th>\n",
       "      <th>Cabin_D</th>\n",
       "      <th>Cabin_E</th>\n",
       "      <th>Cabin_F</th>\n",
       "      <th>Cabin_G</th>\n",
       "      <th>Cabin_None</th>\n",
       "      <th>Cabin_T</th>\n",
       "      <th>Embarked_C</th>\n",
       "      <th>Embarked_Missing</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Embarked_S</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>495</td>\n",
       "      <td>3</td>\n",
       "      <td>29.699118</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>14.4583</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216</th>\n",
       "      <td>216</td>\n",
       "      <td>3</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>109</td>\n",
       "      <td>3</td>\n",
       "      <td>29.699118</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>24.1500</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>842</th>\n",
       "      <td>842</td>\n",
       "      <td>1</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>31.0000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>696</th>\n",
       "      <td>696</td>\n",
       "      <td>3</td>\n",
       "      <td>44.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     index  Pclass        Age  SibSp  Parch     Fare  Sex_female  Sex_male  \\\n",
       "495    495       3  29.699118      0      0  14.4583         0.0       1.0   \n",
       "216    216       3  27.000000      0      0   7.9250         1.0       0.0   \n",
       "109    109       3  29.699118      1      0  24.1500         1.0       0.0   \n",
       "842    842       1  30.000000      0      0  31.0000         1.0       0.0   \n",
       "696    696       3  44.000000      0      0   8.0500         0.0       1.0   \n",
       "\n",
       "     Cabin_A  Cabin_B     ...      Cabin_D  Cabin_E  Cabin_F  Cabin_G  \\\n",
       "495      0.0      0.0     ...          0.0      0.0      0.0      0.0   \n",
       "216      0.0      0.0     ...          0.0      0.0      0.0      0.0   \n",
       "109      0.0      0.0     ...          0.0      0.0      0.0      0.0   \n",
       "842      0.0      0.0     ...          0.0      0.0      0.0      0.0   \n",
       "696      0.0      0.0     ...          0.0      0.0      0.0      0.0   \n",
       "\n",
       "     Cabin_None  Cabin_T  Embarked_C  Embarked_Missing  Embarked_Q  Embarked_S  \n",
       "495         1.0      0.0         1.0               0.0         0.0         0.0  \n",
       "216         1.0      0.0         0.0               0.0         0.0         1.0  \n",
       "109         1.0      0.0         0.0               0.0         1.0         0.0  \n",
       "842         1.0      0.0         1.0               0.0         0.0         0.0  \n",
       "696         1.0      0.0         0.0               0.0         0.0         1.0  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([u'index', u'Pclass', u'Age', u'SibSp', u'Parch', u'Fare', u'Sex_female',\n",
       "       u'Sex_male', u'Cabin_A', u'Cabin_B', u'Cabin_C', u'Cabin_D', u'Cabin_E',\n",
       "       u'Cabin_F', u'Cabin_G', u'Cabin_None', u'Cabin_T', u'Embarked_C',\n",
       "       u'Embarked_Missing', u'Embarked_Q', u'Embarked_S'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this is now wrong since I re-ran it. Need to open a new notebook and start over\n",
    "x_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "messy_model_analytic = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.81287425149700598"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messy_model_analytic.fit(x_train, y_train)\n",
    "messy_model_analytic.score(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 1, 1, 0])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mess_predictions = messy_model_analytic.predict(x_train)\n",
    "mess_predictions[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.8257299 ,  0.1742701 ],\n",
       "       [ 0.32940955,  0.67059045],\n",
       "       [ 0.39377567,  0.60622433],\n",
       "       ..., \n",
       "       [ 0.90263035,  0.09736965],\n",
       "       [ 0.02240288,  0.97759712],\n",
       "       [ 0.81954899,  0.18045101]])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mess_predict_proba = messy_model_analytic.predict_proba(x_train)\n",
    "mess_predict_proba[0:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[347,  53],\n",
       "       [ 72, 196]])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_train, mess_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.83      0.87      0.85       400\n",
      "          1       0.79      0.73      0.76       268\n",
      "\n",
      "avg / total       0.81      0.81      0.81       668\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print classification_report(y_train, mess_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x117c8c150>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAV4AAAD9CAYAAAD01B/uAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x117a7a250>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.heatmap(confusion_matrix(y_train, mess_predictions), annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7847533632286996"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messy_model_analytic.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Model did a little worse on the test data. Precision looked good with train data though. Let's see about the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.01961518,  0.98038482],\n",
       "       [ 0.0988821 ,  0.9011179 ],\n",
       "       [ 0.35210119,  0.64789881],\n",
       "       [ 0.62620723,  0.37379277],\n",
       "       [ 0.85605972,  0.14394028]])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mess_predictions_test = messy_model_analytic.predict(x_test)\n",
    "mess_predict_proba_test = messy_model_analytic.predict_proba(x_test)\n",
    "mess_predict_proba_test[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[120,  29],\n",
       "       [ 19,  55]])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, mess_predictions_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.86      0.81      0.83       149\n",
      "          1       0.65      0.74      0.70        74\n",
      "\n",
      "avg / total       0.79      0.78      0.79       223\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print classification_report(y_test, mess_predictions_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x11a669110>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAV4AAAECCAYAAAC2Z7+WAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nswYAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11a0cec50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.heatmap(confusion_matrix(y_test, mess_predictions_test), annot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Looks as though the test model had a higher score in predicting death, but a lower average precision than on the train data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That is a pretty good score. It also contains quite a lot of columns. Could it be overfit? Should I move into a grid search before running my model on my test data. Also, I may pluck some x variables out for fun and see how it alters my score. Also, need confusion matrix at some point. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "xs = x_train[['Sex_female', 'Age', 'Embarked_Q', \n",
    "             'Cabin_F','Pclass']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "paired_down_model = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.79191616766467066"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# not as good of a score with my plucked x variables (but still decent)\n",
    "paired_down_model.fit(xs, y_train)\n",
    "paired_down_model.score(xs, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 1, 1, 0])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = paired_down_model.predict(xs)\n",
    "predictions[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.90492651,  0.09507349],\n",
       "       [ 0.41647556,  0.58352444],\n",
       "       [ 0.36463247,  0.63536753],\n",
       "       [ 0.07368423,  0.92631577],\n",
       "       [ 0.93662297,  0.06337703]])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_proba = paired_down_model.predict_proba(xs)\n",
    "predict_proba[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sex_female</th>\n",
       "      <th>Age</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Cabin_F</th>\n",
       "      <th>Pclass</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>0.0</td>\n",
       "      <td>29.699118</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Sex_female        Age  Embarked_Q  Cabin_F  Pclass\n",
       "495         0.0  29.699118         0.0      0.0       3"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xs.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The predict_proba shows the probability each variable points to whether or not someone survived. First column predicts the variables possible association to death and second life."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Going to do a confusion matrix now to check for accuracy and evaluate model fit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predicted_dead</th>\n",
       "      <th>predicted_alive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>is_dead</th>\n",
       "      <td>333</td>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is_alive</th>\n",
       "      <td>72</td>\n",
       "      <td>196</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          predicted_dead  predicted_alive\n",
       "is_dead              333               67\n",
       "is_alive              72              196"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confuse_matrix_1 = np.array(confusion_matrix(y_train, predictions))\n",
    "\n",
    "confusion = pd.DataFrame(confuse_matrix_1, index=['is_dead', 'is_alive'],\n",
    "                         columns=['predicted_dead', 'predicted_alive'])\n",
    "\n",
    "confusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The confusion matrix above details the predictions of my model. Its shows that it correctly predicted 356 correctly dead and 176 alive. It returned 78 false positives and 58 false negatives. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's plot the ROC curve to get a visual representation of the confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([ 0.    ,  0.    ,  0.    ,  0.    ,  0.    ,  0.    ,  0.    ,\n",
      "        0.    ,  0.    ,  0.    ,  0.    ,  0.    ,  0.    ,  0.    ,\n",
      "        0.    ,  0.    ,  0.    ,  0.    ,  0.    ,  0.    ,  0.0025,\n",
      "        0.0025,  0.0025,  0.0025,  0.0025,  0.0025,  0.0025,  0.0025,\n",
      "        0.005 ,  0.005 ,  0.005 ,  0.005 ,  0.0075,  0.01  ,  0.01  ,\n",
      "        0.01  ,  0.01  ,  0.01  ,  0.01  ,  0.01  ,  0.01  ,  0.01  ,\n",
      "        0.0125,  0.0125,  0.0175,  0.0175,  0.02  ,  0.02  ,  0.02  ,\n",
      "        0.02  ,  0.02  ,  0.0225,  0.0225,  0.025 ,  0.025 ,  0.025 ,\n",
      "        0.0275,  0.035 ,  0.0375,  0.0375,  0.04  ,  0.04  ,  0.04  ,\n",
      "        0.04  ,  0.0425,  0.045 ,  0.045 ,  0.0475,  0.0475,  0.05  ,\n",
      "        0.05  ,  0.0525,  0.0525,  0.055 ,  0.065 ,  0.0675,  0.0725,\n",
      "        0.075 ,  0.0775,  0.08  ,  0.0825,  0.0825,  0.085 ,  0.0875,\n",
      "        0.09  ,  0.09  ,  0.095 ,  0.1   ,  0.1025,  0.1225,  0.125 ,\n",
      "        0.125 ,  0.1275,  0.1275,  0.13  ,  0.13  ,  0.1325,  0.1325,\n",
      "        0.135 ,  0.135 ,  0.14  ,  0.1625,  0.1675,  0.1675,  0.17  ,\n",
      "        0.1725,  0.1725,  0.1775,  0.1775,  0.1775,  0.18  ,  0.1825,\n",
      "        0.1825,  0.1875,  0.1875,  0.1925,  0.1975,  0.2   ,  0.2   ,\n",
      "        0.2025,  0.2025,  0.2075,  0.21  ,  0.22  ,  0.22  ,  0.2225,\n",
      "        0.2275,  0.2325,  0.2375,  0.2425,  0.25  ,  0.25  ,  0.2525,\n",
      "        0.2575,  0.2625,  0.2675,  0.27  ,  0.2825,  0.2875,  0.295 ,\n",
      "        0.305 ,  0.31  ,  0.3175,  0.3225,  0.3325,  0.3375,  0.34  ,\n",
      "        0.355 ,  0.36  ,  0.3675,  0.37  ,  0.3775,  0.3825,  0.39  ,\n",
      "        0.3975,  0.4   ,  0.4   ,  0.405 ,  0.4125,  0.415 ,  0.415 ,\n",
      "        0.42  ,  0.42  ,  0.4275,  0.43  ,  0.4475,  0.4575,  0.4775,\n",
      "        0.4825,  0.49  ,  0.5075,  0.5225,  0.5225,  0.5725,  0.5925,\n",
      "        0.595 ,  0.6125,  0.6175,  0.635 ,  0.64  ,  0.6475,  0.65  ,\n",
      "        0.6625,  0.665 ,  0.68  ,  0.6825,  0.7   ,  0.705 ,  0.725 ,\n",
      "        0.73  ,  0.7325,  0.745 ,  0.8675,  0.8825,  0.8875,  0.89  ,\n",
      "        0.8925,  0.895 ,  0.9075,  0.9125,  0.915 ,  0.92  ,  0.93  ,\n",
      "        0.9325,  0.9375,  0.945 ,  0.95  ,  0.9525,  0.9675,  0.97  ,\n",
      "        0.975 ,  0.9775,  0.985 ,  1.    ]), array([ 0.00373134,  0.00746269,  0.01492537,  0.01865672,  0.04104478,\n",
      "        0.05597015,  0.06343284,  0.06716418,  0.0858209 ,  0.09328358,\n",
      "        0.11940299,  0.13432836,  0.14179104,  0.1641791 ,  0.16791045,\n",
      "        0.17537313,  0.19029851,  0.23880597,  0.25373134,  0.25746269,\n",
      "        0.25746269,  0.28731343,  0.29477612,  0.30223881,  0.30970149,\n",
      "        0.31343284,  0.32089552,  0.32835821,  0.33955224,  0.34328358,\n",
      "        0.35074627,  0.35447761,  0.35447761,  0.35820896,  0.36940299,\n",
      "        0.37686567,  0.38432836,  0.39179104,  0.39925373,  0.40298507,\n",
      "        0.4141791 ,  0.42164179,  0.42164179,  0.42910448,  0.43283582,\n",
      "        0.44402985,  0.44402985,  0.44776119,  0.45895522,  0.46641791,\n",
      "        0.4738806 ,  0.4738806 ,  0.47761194,  0.47761194,  0.48507463,\n",
      "        0.48880597,  0.48880597,  0.48880597,  0.48880597,  0.49253731,\n",
      "        0.49253731,  0.49626866,  0.50373134,  0.50746269,  0.51119403,\n",
      "        0.51119403,  0.51492537,  0.51492537,  0.51865672,  0.52238806,\n",
      "        0.5261194 ,  0.53731343,  0.54477612,  0.54477612,  0.60447761,\n",
      "        0.60447761,  0.60820896,  0.61940299,  0.61940299,  0.62313433,\n",
      "        0.63432836,  0.6380597 ,  0.6380597 ,  0.64552239,  0.64552239,\n",
      "        0.65298507,  0.65298507,  0.65298507,  0.65298507,  0.66791045,\n",
      "        0.67164179,  0.67910448,  0.68283582,  0.68656716,  0.68656716,\n",
      "        0.69776119,  0.70149254,  0.70522388,  0.71268657,  0.71641791,\n",
      "        0.71641791,  0.73134328,  0.73134328,  0.73507463,  0.73880597,\n",
      "        0.73880597,  0.74253731,  0.74253731,  0.74626866,  0.75746269,\n",
      "        0.75746269,  0.76865672,  0.77238806,  0.77238806,  0.7761194 ,\n",
      "        0.77985075,  0.77985075,  0.78358209,  0.78731343,  0.78731343,\n",
      "        0.79477612,  0.79850746,  0.79850746,  0.79850746,  0.80597015,\n",
      "        0.81343284,  0.81716418,  0.82462687,  0.82462687,  0.82462687,\n",
      "        0.82462687,  0.82835821,  0.83208955,  0.8358209 ,  0.8358209 ,\n",
      "        0.8358209 ,  0.83955224,  0.83955224,  0.83955224,  0.83955224,\n",
      "        0.83955224,  0.83955224,  0.83955224,  0.83955224,  0.83955224,\n",
      "        0.83955224,  0.83955224,  0.84701493,  0.84701493,  0.85074627,\n",
      "        0.85447761,  0.85447761,  0.85820896,  0.85820896,  0.85820896,\n",
      "        0.85820896,  0.8619403 ,  0.86567164,  0.86567164,  0.86567164,\n",
      "        0.87313433,  0.87313433,  0.87686567,  0.87686567,  0.88432836,\n",
      "        0.88432836,  0.88432836,  0.8880597 ,  0.8880597 ,  0.8880597 ,\n",
      "        0.89179104,  0.89552239,  0.89925373,  0.90298507,  0.9141791 ,\n",
      "        0.9141791 ,  0.9141791 ,  0.9141791 ,  0.91791045,  0.91791045,\n",
      "        0.91791045,  0.91791045,  0.92164179,  0.92164179,  0.92537313,\n",
      "        0.92537313,  0.93283582,  0.94402985,  0.94402985,  0.94402985,\n",
      "        0.94402985,  0.95149254,  0.97014925,  0.9738806 ,  0.9738806 ,\n",
      "        0.97761194,  0.99626866,  0.99626866,  0.99626866,  0.99626866,\n",
      "        0.99626866,  0.99626866,  0.99626866,  0.99626866,  0.99626866,\n",
      "        1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
      "        1.        ,  1.        ,  1.        ,  1.        ]), array([  3.02367659e+00,   2.99291095e+00,   2.96214532e+00,\n",
      "         2.93137968e+00,   2.80831713e+00,   2.77755150e+00,\n",
      "         2.74678586e+00,   2.74022471e+00,   2.71602022e+00,\n",
      "         2.56219204e+00,   2.54068324e+00,   2.53142640e+00,\n",
      "         2.43912949e+00,   2.37759822e+00,   2.34683258e+00,\n",
      "         2.28530131e+00,   2.25453567e+00,   2.00841058e+00,\n",
      "         1.94687930e+00,   1.92076653e+00,   1.91611367e+00,\n",
      "         1.73151985e+00,   1.72661603e+00,   1.68928925e+00,\n",
      "         1.66998857e+00,   1.66508476e+00,   1.63431912e+00,\n",
      "         1.60355349e+00,   1.57278785e+00,   1.54692602e+00,\n",
      "         1.54202221e+00,   1.51616039e+00,   1.51125658e+00,\n",
      "         1.48049094e+00,   1.44972530e+00,   1.39745087e+00,\n",
      "         1.38819403e+00,   1.31127994e+00,   1.29589712e+00,\n",
      "         1.26513148e+00,   1.20360021e+00,   1.14485653e+00,\n",
      "         1.14206893e+00,   1.13716512e+00,   1.10639949e+00,\n",
      "         1.08053766e+00,   1.07563385e+00,   1.04977202e+00,\n",
      "         1.04486821e+00,   1.01900639e+00,   1.00754143e+00,\n",
      "         9.83336939e-01,   9.76775789e-01,   9.57475113e-01,\n",
      "         9.26709476e-01,   9.18669038e-01,   9.15244515e-01,\n",
      "         8.91040028e-01,   8.29508755e-01,   8.23910877e-01,\n",
      "         8.22947605e-01,   7.92181968e-01,   7.72881292e-01,\n",
      "         7.67977481e-01,   7.37211844e-01,   7.21829026e-01,\n",
      "         7.06446207e-01,   6.75680570e-01,   6.49818745e-01,\n",
      "         6.44914934e-01,   6.19053108e-01,   6.14149297e-01,\n",
      "         5.83383660e-01,   5.57521835e-01,   5.55313711e-01,\n",
      "         5.52618023e-01,   5.21852386e-01,   4.91086750e-01,\n",
      "         4.84525600e-01,   4.60321113e-01,   4.29555476e-01,\n",
      "         4.23957598e-01,   3.98789839e-01,   3.68024202e-01,\n",
      "         3.62426325e-01,   3.37258565e-01,   3.00895051e-01,\n",
      "         2.75727292e-01,   2.70129414e-01,   2.54218492e-01,\n",
      "         2.44961655e-01,   2.39363777e-01,   2.14196018e-01,\n",
      "         2.13251008e-01,   2.08598141e-01,   1.47066867e-01,\n",
      "         1.16301230e-01,   9.11334709e-02,   8.55355933e-02,\n",
      "         6.03678340e-02,   5.47699565e-02,   3.32611569e-02,\n",
      "         2.40043197e-02,  -1.16343960e-03,  -6.76131716e-03,\n",
      "        -3.19290764e-02,  -3.75269540e-02,  -9.34603501e-02,\n",
      "        -9.90582276e-02,  -1.29823864e-01,  -1.54991624e-01,\n",
      "        -1.60589501e-01,  -1.91355138e-01,  -2.16522897e-01,\n",
      "        -2.21794428e-01,  -2.22120775e-01,  -2.78054171e-01,\n",
      "        -2.83652049e-01,  -2.88555860e-01,  -3.08819808e-01,\n",
      "        -3.45183322e-01,  -4.37480233e-01,  -4.52863051e-01,\n",
      "        -4.99011506e-01,  -5.29777143e-01,  -5.60542780e-01,\n",
      "        -5.91308417e-01,  -6.52839690e-01,  -6.88509139e-01,\n",
      "        -7.45136601e-01,  -7.50040412e-01,  -7.70304360e-01,\n",
      "        -7.75902238e-01,  -7.80806049e-01,  -8.37433511e-01,\n",
      "        -8.42337323e-01,  -8.98964785e-01,  -9.03868596e-01,\n",
      "        -9.29730422e-01,  -9.34634233e-01,  -9.65399870e-01,\n",
      "        -1.02202733e+00,  -1.02693114e+00,  -1.05279297e+00,\n",
      "        -1.05769678e+00,  -1.08846242e+00,  -1.09992738e+00,\n",
      "        -1.10997122e+00,  -1.11922805e+00,  -1.14999369e+00,\n",
      "        -1.18075933e+00,  -1.23738679e+00,  -1.24229060e+00,\n",
      "        -1.28452120e+00,  -1.30382188e+00,  -1.33458751e+00,\n",
      "        -1.35241289e+00,  -1.37025696e+00,  -1.39611879e+00,\n",
      "        -1.40102260e+00,  -1.43178823e+00,  -1.46255387e+00,\n",
      "        -1.48841570e+00,  -1.61147824e+00,  -1.61638205e+00,\n",
      "        -1.76530643e+00,  -1.79607206e+00,  -1.83174151e+00,\n",
      "        -1.85760334e+00,  -1.86250715e+00,  -1.89327279e+00,\n",
      "        -1.92403842e+00,  -1.93059957e+00,  -1.95210837e+00,\n",
      "        -1.95480406e+00,  -1.97018688e+00,  -1.98556970e+00,\n",
      "        -2.01143152e+00,  -2.01633533e+00,  -2.04219716e+00,\n",
      "        -2.04710097e+00,  -2.06248379e+00,  -2.07786661e+00,\n",
      "        -2.09324943e+00,  -2.10863224e+00,  -2.12984120e+00,\n",
      "        -2.13939788e+00,  -2.17016352e+00,  -2.20092915e+00,\n",
      "        -2.21631197e+00,  -2.22679098e+00,  -2.23169479e+00,\n",
      "        -2.25320359e+00,  -2.26246043e+00,  -2.27784325e+00,\n",
      "        -2.29322606e+00,  -2.32399170e+00,  -2.34985353e+00,\n",
      "        -2.35475734e+00,  -2.38552298e+00,  -2.40090579e+00,\n",
      "        -2.41628861e+00,  -2.44705425e+00,  -2.47781989e+00,\n",
      "        -2.50858552e+00,  -2.53935116e+00,  -2.57011680e+00,\n",
      "        -2.60088243e+00,  -2.69317934e+00,  -2.72394498e+00,\n",
      "        -2.78547625e+00,  -2.84700753e+00,  -2.90853880e+00,\n",
      "        -3.61614845e+00]))\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAqcAAAI+CAYAAACBjKOPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11a91e5d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_score = paired_down_model.decision_function(xs)\n",
    "\n",
    "FPR = dict()\n",
    "TPR = dict()\n",
    "ROC_AUC = dict() # {}\n",
    "\n",
    "# For class 1, find the area under the curve\n",
    "\n",
    "print roc_curve(y_train, y_score)\n",
    "\n",
    "FPR[1], TPR[1], _ = roc_curve(y_train, y_score)\n",
    "ROC_AUC[1] = auc(FPR[1], TPR[1])\n",
    "\n",
    "\n",
    "# Plot of a ROC curve for class 1 (Survival)\n",
    "plt.figure(figsize=[11,9])\n",
    "plt.plot(FPR[1], TPR[1], label='ROC curve (area = %0.2f)' % ROC_AUC[1], linewidth=4)\n",
    "plt.plot([0, 1], [0, 1], 'k--', linewidth=4)\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate', fontsize=18)\n",
    "plt.ylabel('True Positive Rate', fontsize=18)\n",
    "plt.title('Variables Predicting Survival', fontsize=18)\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The greater the area under the curve shows the higher the ratio of true positives to false positives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.79191616766467066"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc = accuracy_score(y_train, predictions)\n",
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.82      0.83      0.83       400\n",
      "          1       0.75      0.73      0.74       268\n",
      "\n",
      "avg / total       0.79      0.79      0.79       668\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_train, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even though I have higher scoring models than this one I am going to go ahead and run it on my test data just for practice."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pulled the info below from notes to go over what my confusion matrix means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# The 0 and 1 on the left column indicate the two classes predicted by the model. For models with multiple classes there would be more rows and labels.\n",
    "\n",
    "# Each of the columns indicate an important metric for evaluating classification model performance.\n",
    "\n",
    "# Precision is the ability of the classifier to avoid mislabeling when the observation belongs in another class.\n",
    "\n",
    "# Precision = True Positives / (True Positives + False Positives)\n",
    "\n",
    "# A precision score of 1 indicates that the classifier never mistakenly added observations from another class. A precision score of 0 would mean that the classifier misclassified every instance of the current class.\n",
    "\n",
    "# recall is the ability of the classifier to correctly identify all observations in the current class.\n",
    "\n",
    "# Recall = True Positives / (True Positives + False Negatives)\n",
    "\n",
    "# A recall score of 1 indicates that the classifier correctly predicted (found) all observations of the current class (by implication, no false negatives, or misclassifications of the current class). A recall score of 0 alternatively means that the classifier missed all observations of the current class.\n",
    "\n",
    "# f1-score is the harmonic mean of the precision and recall. The harmonic mean is used here rather than the more conventional arithmetic mean because the harmonic mean is more appropriate for averaging rates.\n",
    "\n",
    "# F1-Score = 2 * (Precision * Recall) / (Precision + Recall)\n",
    "\n",
    "# The f1-score's best value is 1 and worst value is 0, like the precision and recall scores. It is a useful metric for taking into account both measures at once.\n",
    "\n",
    "# support is simply the number of observations of the labelled class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "xs_test = x_test[['Sex_female', 'Age', 'Embarked_Q', \n",
    "             'Cabin_F','Pclass']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using paired_down_model with test data we get: 0.77130044843\n"
     ]
    }
   ],
   "source": [
    "print 'Using paired_down_model with test data we get:', paired_down_model.score(xs_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0.7919161 <-- was score from train data. When compared to test data, test data did not have a higher score. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's not surprising that 'Sex_female', 'Age', and 'Pclass' variables did well in identifying whether or not a passenger survived. Through historical records we know that women, children, and first class passengers where given priority when boarding life boats."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will do a grid search on the train data to see what kind of scores return."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "parameters = {\n",
    "    'penalty': ['l1', 'l2'],\n",
    "    'C': [0.1, 1, 10, 5, .001]\n",
    "}\n",
    "paired_down_model = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=6, error_score='raise',\n",
       "       estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False),\n",
       "       fit_params={}, iid=True, n_jobs=1,\n",
       "       param_grid={'penalty': ['l1', 'l2'], 'C': [0.1, 1, 10, 5, 0.001]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, scoring=None, verbose=10)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search = GridSearchCV(estimator=paired_down_model,\n",
    "                          param_grid=parameters,\n",
    "                          verbose=10,\n",
    "                          cv=6)\n",
    "grid_search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 6 folds for each of 10 candidates, totalling 60 fits\n",
      "[CV] penalty=l1, C=0.1 ...............................................\n",
      "[CV] ...................... penalty=l1, C=0.1, score=0.866071 -   0.0s\n",
      "[CV] penalty=l1, C=0.1 ...............................................\n",
      "[CV] ...................... penalty=l1, C=0.1, score=0.758929 -   0.0s\n",
      "[CV] penalty=l1, C=0.1 ...............................................\n",
      "[CV] ...................... penalty=l1, C=0.1, score=0.678571 -   0.0s\n",
      "[CV] penalty=l1, C=0.1 ...............................................\n",
      "[CV] ...................... penalty=l1, C=0.1, score=0.803571 -   0.0s\n",
      "[CV] penalty=l1, C=0.1 ...............................................\n",
      "[CV] ...................... penalty=l1, C=0.1, score=0.781818 -   0.0s\n",
      "[CV] penalty=l1, C=0.1 ...............................................\n",
      "[CV] ...................... penalty=l1, C=0.1, score=0.827273 -   0.0s\n",
      "[CV] penalty=l2, C=0.1 ...............................................\n",
      "[CV] ...................... penalty=l2, C=0.1, score=0.875000 -   0.0s\n",
      "[CV] penalty=l2, C=0.1 ...............................................\n",
      "[CV] ...................... penalty=l2, C=0.1, score=0.758929 -   0.0s\n",
      "[CV] penalty=l2, C=0.1 ...............................................\n",
      "[CV] ...................... penalty=l2, C=0.1, score=0.678571 -   0.0s\n",
      "[CV] penalty=l2, C=0.1 ...............................................\n",
      "[CV] ...................... penalty=l2, C=0.1, score=0.803571 -   0.0s\n",
      "[CV] penalty=l2, C=0.1 ...............................................\n",
      "[CV] ...................... penalty=l2, C=0.1, score=0.790909 -   0.0s\n",
      "[CV] penalty=l2, C=0.1 ...............................................\n",
      "[CV] ...................... penalty=l2, C=0.1, score=0.836364 -   0.0s\n",
      "[CV] penalty=l1, C=1 .................................................\n",
      "[CV] ........................ penalty=l1, C=1, score=0.866071 -   0.0s\n",
      "[CV] penalty=l1, C=1 .................................................\n",
      "[CV] ........................ penalty=l1, C=1, score=0.767857 -   0.0s\n",
      "[CV] penalty=l1, C=1 .................................................\n",
      "[CV] ........................ penalty=l1, C=1, score=0.705357 -   0.0s\n",
      "[CV] penalty=l1, C=1 .................................................\n",
      "[CV] ........................ penalty=l1, C=1, score=0.821429 -   0.0s\n",
      "[CV] penalty=l1, C=1 .................................................\n",
      "[CV] ........................ penalty=l1, C=1, score=0.745455 -   0.0s\n",
      "[CV] penalty=l1, C=1 .................................................\n",
      "[CV] ........................ penalty=l1, C=1, score=0.818182 -   0.0s\n",
      "[CV] penalty=l2, C=1 .................................................\n",
      "[CV] ........................ penalty=l2, C=1, score=0.866071 -   0.0s\n",
      "[CV] penalty=l2, C=1 .................................................\n",
      "[CV] ........................ penalty=l2, C=1, score=0.776786 -   0.0s\n",
      "[CV] penalty=l2, C=1 .................................................\n",
      "[CV] ........................ penalty=l2, C=1, score=0.714286 -   0.0s\n",
      "[CV] penalty=l2, C=1 .................................................\n",
      "[CV] ........................ penalty=l2, C=1, score=0.821429 -   0.0s\n",
      "[CV] penalty=l2, C=1 .................................................\n",
      "[CV] ........................ penalty=l2, C=1, score=0.745455 -   0.0s\n",
      "[CV] penalty=l2, C=1 .................................................\n",
      "[CV] ........................ penalty=l2, C=1, score=0.818182 -   0.0s\n",
      "[CV] penalty=l1, C=10 ................................................\n",
      "[CV] ....................... penalty=l1, C=10, score=0.866071 -   0.0s\n",
      "[CV] penalty=l1, C=10 ................................................\n",
      "[CV] ....................... penalty=l1, C=10, score=0.776786 -   0.0s\n",
      "[CV] penalty=l1, C=10 ................................................\n",
      "[CV] ....................... penalty=l1, C=10, score=0.714286 -   0.0s\n",
      "[CV] penalty=l1, C=10 ................................................\n",
      "[CV] ....................... penalty=l1, C=10, score=0.821429 -   0.0s\n",
      "[CV] penalty=l1, C=10 ................................................\n",
      "[CV] ....................... penalty=l1, C=10, score=0.754545 -   0.0s\n",
      "[CV] penalty=l1, C=10 ................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 tasks       | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 tasks       | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 tasks       | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  12 tasks       | elapsed:    0.1s\n",
      "[Parallel(n_jobs=1)]: Done  17 tasks       | elapsed:    0.1s\n",
      "[Parallel(n_jobs=1)]: Done  24 tasks       | elapsed:    0.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ....................... penalty=l1, C=10, score=0.818182 -   0.0s\n",
      "[CV] penalty=l2, C=10 ................................................\n",
      "[CV] ....................... penalty=l2, C=10, score=0.866071 -   0.0s\n",
      "[CV] penalty=l2, C=10 ................................................\n",
      "[CV] ....................... penalty=l2, C=10, score=0.776786 -   0.0s\n",
      "[CV] penalty=l2, C=10 ................................................\n",
      "[CV] ....................... penalty=l2, C=10, score=0.714286 -   0.0s\n",
      "[CV] penalty=l2, C=10 ................................................\n",
      "[CV] ....................... penalty=l2, C=10, score=0.821429 -   0.0s\n",
      "[CV] penalty=l2, C=10 ................................................\n",
      "[CV] ....................... penalty=l2, C=10, score=0.754545 -   0.0s\n",
      "[CV] penalty=l2, C=10 ................................................\n",
      "[CV] ....................... penalty=l2, C=10, score=0.818182 -   0.0s\n",
      "[CV] penalty=l1, C=5 .................................................\n",
      "[CV] ........................ penalty=l1, C=5, score=0.866071 -   0.0s\n",
      "[CV] penalty=l1, C=5 .................................................\n",
      "[CV] ........................ penalty=l1, C=5, score=0.776786 -   0.0s\n",
      "[CV] penalty=l1, C=5 .................................................\n",
      "[CV] ........................ penalty=l1, C=5, score=0.705357 -   0.0s\n",
      "[CV] penalty=l1, C=5 .................................................\n",
      "[CV] ........................ penalty=l1, C=5, score=0.821429 -   0.0s\n",
      "[CV] penalty=l1, C=5 .................................................\n",
      "[CV] ........................ penalty=l1, C=5, score=0.754545 -   0.0s\n",
      "[CV] penalty=l1, C=5 .................................................\n",
      "[CV] ........................ penalty=l1, C=5, score=0.818182 -   0.0s\n",
      "[CV] penalty=l2, C=5 .................................................\n",
      "[CV] ........................ penalty=l2, C=5, score=0.866071 -   0.0s\n",
      "[CV] penalty=l2, C=5 .................................................\n",
      "[CV] ........................ penalty=l2, C=5, score=0.776786 -   0.0s\n",
      "[CV] penalty=l2, C=5 .................................................\n",
      "[CV] ........................ penalty=l2, C=5, score=0.696429 -   0.0s\n",
      "[CV] penalty=l2, C=5 .................................................\n",
      "[CV] ........................ penalty=l2, C=5, score=0.821429 -   0.0s\n",
      "[CV] penalty=l2, C=5 .................................................\n",
      "[CV] ........................ penalty=l2, C=5, score=0.754545 -   0.0s\n",
      "[CV] penalty=l2, C=5 .................................................\n",
      "[CV] ........................ penalty=l2, C=5, score=0.818182 -   0.0s\n",
      "[CV] penalty=l1, C=0.001 .............................................\n",
      "[CV] .................... penalty=l1, C=0.001, score=0.598214 -   0.0s\n",
      "[CV] penalty=l1, C=0.001 .............................................\n",
      "[CV] .................... penalty=l1, C=0.001, score=0.598214 -   0.0s\n",
      "[CV] penalty=l1, C=0.001 .............................................\n",
      "[CV] .................... penalty=l1, C=0.001, score=0.598214 -   0.0s\n",
      "[CV] penalty=l1, C=0.001 .............................................\n",
      "[CV] .................... penalty=l1, C=0.001, score=0.598214 -   0.0s\n",
      "[CV] penalty=l1, C=0.001 .............................................\n",
      "[CV] .................... penalty=l1, C=0.001, score=0.600000 -   0.0s\n",
      "[CV] penalty=l1, C=0.001 .............................................\n",
      "[CV] .................... penalty=l1, C=0.001, score=0.600000 -   0.0s\n",
      "[CV] penalty=l2, C=0.001 .............................................\n",
      "[CV] .................... penalty=l2, C=0.001, score=0.598214 -   0.0s\n",
      "[CV] penalty=l2, C=0.001 .............................................\n",
      "[CV] .................... penalty=l2, C=0.001, score=0.598214 -   0.0s\n",
      "[CV] penalty=l2, C=0.001 .............................................\n",
      "[CV] .................... penalty=l2, C=0.001, score=0.598214 -   0.0s\n",
      "[CV] penalty=l2, C=0.001 .............................................\n",
      "[CV] .................... penalty=l2, C=0.001, score=0.598214 -   0.0s\n",
      "[CV] penalty=l2, C=0.001 .............................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  31 tasks       | elapsed:    0.2s\n",
      "[Parallel(n_jobs=1)]: Done  40 tasks       | elapsed:    0.3s\n",
      "[Parallel(n_jobs=1)]: Done  49 tasks       | elapsed:    0.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .................... penalty=l2, C=0.001, score=0.600000 -   0.0s\n",
      "[CV] penalty=l2, C=0.001 .............................................\n",
      "[CV] .................... penalty=l2, C=0.001, score=0.600000 -   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  60 tasks       | elapsed:    0.4s\n",
      "[Parallel(n_jobs=1)]: Done  60 out of  60 | elapsed:    0.4s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=6, error_score='raise',\n",
       "       estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False),\n",
       "       fit_params={}, iid=True, n_jobs=1,\n",
       "       param_grid={'penalty': ['l1', 'l2'], 'C': [0.1, 1, 10, 5, 0.001]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, scoring=None, verbose=10)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.fit(xs, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.79191616766467066"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=10, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=10, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_estimator_.fit(xs, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.79491017964071853"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_estimator_.score(xs, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictors = grid_search.best_estimator_.predict(xs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[333,  67],\n",
       "       [ 70, 198]])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_train, predictors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predicted_dead</th>\n",
       "      <th>predicted_alive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>is_dead</th>\n",
       "      <td>333</td>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is_alive</th>\n",
       "      <td>72</td>\n",
       "      <td>196</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          predicted_dead  predicted_alive\n",
       "is_dead              333               67\n",
       "is_alive              72              196"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confuse_matrix_1 = np.array(confusion_matrix(y_train, predictions))\n",
    "\n",
    "confusion = pd.DataFrame(confuse_matrix_1, index=['is_dead', 'is_alive'],\n",
    "                         columns=['predicted_dead', 'predicted_alive'])\n",
    "\n",
    "confusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.83      0.83      0.83       400\n",
      "          1       0.75      0.74      0.74       268\n",
      "\n",
      "avg / total       0.79      0.79      0.79       668\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print classification_report(y_train, predictors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x11ab2ac90>"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAV4AAAD9CAYAAAD01B/uAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nVM0XAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11ab2a150>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.heatmap(confusion_matrix(y_train, predictors), annot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Before I accept this model I want to go back and restrain my x variables to be old age, male, first class, and missing embarked location."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pclass=1</th>\n",
       "      <th>pclass=2</th>\n",
       "      <th>Sex_male</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Embarked_Missing</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Embarked_S</th>\n",
       "      <th>Child</th>\n",
       "      <th>Old Person</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pclass=1  pclass=2  Sex_male   Age  SibSp  Parch  Embarked_Missing  \\\n",
       "0       0.0       0.0       1.0  22.0      1      0               0.0   \n",
       "\n",
       "   Embarked_Q  Embarked_S  Child  Old Person  \n",
       "0         0.0         1.0      0           0  "
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analytic_df.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Need to make a train test split on this dataframe. Then I will run a logistic regression on my plucked out x variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_plucked = analytic_df[['pclass=1', 'Sex_male', 'Old Person', 'Embarked_Missing']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(data_plucked, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((668, 4), (668,))"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((223, 4), (223,))"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pluck_model = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pluck_model.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.77694610778443118"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pluck_model.score(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pluck_model_lasso = LogisticRegression(penalty='l1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.77694610778443118"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pluck_model_lasso.fit(x_train, y_train)\n",
    "pluck_model_lasso.score(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, 1, 0])"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict = pluck_model.predict(x_train)\n",
    "predict[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.84261278,  0.15738722],\n",
       "       [ 0.67512232,  0.32487768],\n",
       "       [ 0.33954606,  0.66045394],\n",
       "       ..., \n",
       "       [ 0.84261278,  0.15738722],\n",
       "       [ 0.33954606,  0.66045394],\n",
       "       [ 0.84261278,  0.15738722]])"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_proba = pluck_model.predict_proba(x_train)\n",
    "predict_proba[0:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before modeling on my test data, let's do a confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[340,  64],\n",
       "       [ 85, 179]])"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_train, predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predicted_dead</th>\n",
       "      <th>predicted_alive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>is_dead</th>\n",
       "      <td>340</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is_alive</th>\n",
       "      <td>85</td>\n",
       "      <td>179</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          predicted_dead  predicted_alive\n",
       "is_dead              340               64\n",
       "is_alive              85              179"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confuse_matrix_org = np.array(confusion_matrix(y_train, predict))\n",
    "\n",
    "confusion_org = pd.DataFrame(confuse_matrix_org, index=['is_dead', 'is_alive'],\n",
    "                         columns=['predicted_dead', 'predicted_alive'])\n",
    "\n",
    "confusion_org"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above confusion matrix shows that there were 340 true negatives predicted by the model, 64 false negatives, 85 false positives, and 179 true positives. So, predicting that 64 people survived when they were in fact dead is not too shabby for my model. Let's check precision with a classification report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.80      0.84      0.82       404\n",
      "          1       0.74      0.68      0.71       264\n",
      "\n",
      "avg / total       0.77      0.78      0.78       668\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print classification_report(y_train, predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overall good scores for predicting death. On the other hand it may not be the best model if you are a glass half full kind of person."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x11add4350>"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAV4AAAD9CAYAAAD01B/uAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nrkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11a6f6590>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.heatmap(confusion_matrix(y_train,predict), annot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's run test data through this model now and see what happens to the scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.81614349775784756"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pluck_model.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After passing the test data through the model it shows a higher score. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusion:\n",
    "\n",
    "So, let's recap: I have made three different models. All vary in their predictive power. Best score has been with messy_model_analytic and plucked_model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
