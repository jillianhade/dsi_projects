{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import all the things!\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.cross_validation import KFold\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.grid_search import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = pd.read_csv('../titanic.csv')\n",
    "y = X.pop('Survived')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>714.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>445.000000</td>\n",
       "      <td>446.000000</td>\n",
       "      <td>2.308642</td>\n",
       "      <td>29.699118</td>\n",
       "      <td>0.523008</td>\n",
       "      <td>0.381594</td>\n",
       "      <td>32.204208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>257.353842</td>\n",
       "      <td>257.353842</td>\n",
       "      <td>0.836071</td>\n",
       "      <td>14.526497</td>\n",
       "      <td>1.102743</td>\n",
       "      <td>0.806057</td>\n",
       "      <td>49.693429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>222.500000</td>\n",
       "      <td>223.500000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.910400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>445.000000</td>\n",
       "      <td>446.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.454200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>667.500000</td>\n",
       "      <td>668.500000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>890.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>512.329200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            index  PassengerId      Pclass         Age       SibSp  \\\n",
       "count  891.000000   891.000000  891.000000  714.000000  891.000000   \n",
       "mean   445.000000   446.000000    2.308642   29.699118    0.523008   \n",
       "std    257.353842   257.353842    0.836071   14.526497    1.102743   \n",
       "min      0.000000     1.000000    1.000000    0.420000    0.000000   \n",
       "25%    222.500000   223.500000    2.000000         NaN    0.000000   \n",
       "50%    445.000000   446.000000    3.000000         NaN    0.000000   \n",
       "75%    667.500000   668.500000    3.000000         NaN    1.000000   \n",
       "max    890.000000   891.000000    3.000000   80.000000    8.000000   \n",
       "\n",
       "            Parch        Fare  \n",
       "count  891.000000  891.000000  \n",
       "mean     0.381594   32.204208  \n",
       "std      0.806057   49.693429  \n",
       "min      0.000000    0.000000  \n",
       "25%      0.000000    7.910400  \n",
       "50%      0.000000   14.454200  \n",
       "75%      0.000000   31.000000  \n",
       "max      6.000000  512.329200  "
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.describe()\n",
    "# age has missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>445.000000</td>\n",
       "      <td>446.000000</td>\n",
       "      <td>2.308642</td>\n",
       "      <td>29.699118</td>\n",
       "      <td>0.523008</td>\n",
       "      <td>0.381594</td>\n",
       "      <td>32.204208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>257.353842</td>\n",
       "      <td>257.353842</td>\n",
       "      <td>0.836071</td>\n",
       "      <td>13.002015</td>\n",
       "      <td>1.102743</td>\n",
       "      <td>0.806057</td>\n",
       "      <td>49.693429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>222.500000</td>\n",
       "      <td>223.500000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.910400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>445.000000</td>\n",
       "      <td>446.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>29.699118</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.454200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>667.500000</td>\n",
       "      <td>668.500000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>890.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>512.329200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            index  PassengerId      Pclass         Age       SibSp  \\\n",
       "count  891.000000   891.000000  891.000000  891.000000  891.000000   \n",
       "mean   445.000000   446.000000    2.308642   29.699118    0.523008   \n",
       "std    257.353842   257.353842    0.836071   13.002015    1.102743   \n",
       "min      0.000000     1.000000    1.000000    0.420000    0.000000   \n",
       "25%    222.500000   223.500000    2.000000   22.000000    0.000000   \n",
       "50%    445.000000   446.000000    3.000000   29.699118    0.000000   \n",
       "75%    667.500000   668.500000    3.000000   35.000000    1.000000   \n",
       "max    890.000000   891.000000    3.000000   80.000000    8.000000   \n",
       "\n",
       "            Parch        Fare  \n",
       "count  891.000000  891.000000  \n",
       "mean     0.381594   32.204208  \n",
       "std      0.806057   49.693429  \n",
       "min      0.000000    0.000000  \n",
       "25%      0.000000    7.910400  \n",
       "50%      0.000000   14.454200  \n",
       "75%      0.000000   31.000000  \n",
       "max      6.000000  512.329200  "
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# impute age with mean\n",
    "X['Age'].fillna(X.Age.mean(), inplace=True)\n",
    "\n",
    "# confirm\n",
    "X.describe()\n",
    "\n",
    "# ignoring categorical variables for right now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index  PassengerId  Pclass   Age  SibSp  Parch     Fare\n",
       "0      0            1       3  22.0      1      0   7.2500\n",
       "1      1            2       1  38.0      1      0  71.2833\n",
       "2      2            3       3  26.0      0      0   7.9250\n",
       "3      3            4       1  35.0      1      0  53.1000\n",
       "4      4            5       3  35.0      0      0   8.0500"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# return just numeric variables ignoring 'object' datatypes\n",
    "numeric_variables = list(X.dtypes[X.dtypes != 'object'].index)\n",
    "X[numeric_variables].head()\n",
    "# passenger id seems ignorable "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LogisticRegression()\n",
    "model.fit(X[numeric_variables], y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.70258136924803594"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# not shabby for a quick model to get going, but I think I can get a better score\n",
    "model.score(X[numeric_variables], y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method LogisticRegression.predict_proba of LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)>"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# do predictions to get to confusion matrix\n",
    "# not sure what I was going with this\n",
    "model.predict_proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# function to show descriptive stats on categorical variables\n",
    "def describe_categorical(X):\n",
    "    from IPython.display import display, HTML\n",
    "    display(HTML(X[X.columns[X.dtypes == 'object']].describe().to_html()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>891</td>\n",
       "      <td>891</td>\n",
       "      <td>891</td>\n",
       "      <td>204</td>\n",
       "      <td>889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>891</td>\n",
       "      <td>2</td>\n",
       "      <td>681</td>\n",
       "      <td>147</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>Graham, Mr. George Edward</td>\n",
       "      <td>male</td>\n",
       "      <td>CA. 2343</td>\n",
       "      <td>C23 C25 C27</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>1</td>\n",
       "      <td>577</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>644</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "describe_categorical(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# drop variables I dont want in this\n",
    "X.drop(['Name', 'Ticket', 'PassengerId'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# change cabin variable to be first letter\n",
    "def clean_cabin(x):\n",
    "    try:\n",
    "        return x[0]\n",
    "    except TypeError:\n",
    "        return 'None'\n",
    "    \n",
    "X['Cabin'] = X.Cabin.apply(clean_cabin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    None\n",
       "1       C\n",
       "2    None\n",
       "3       C\n",
       "4    None\n",
       "Name: Cabin, dtype: object"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# if data is missing returns none\n",
    "X.Cabin.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "categorical_variables = ['Sex', 'Cabin', 'Embarked']\n",
    "\n",
    "for variable in categorical_variables:\n",
    "    X[variable].fillna('Missing', inplace=True)\n",
    "    dummies = pd.get_dummies(X[variable], prefix=variable)\n",
    "    X = pd.concat([X, dummies], axis=1)\n",
    "    X.drop([variable], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Sex_female</th>\n",
       "      <th>Sex_male</th>\n",
       "      <th>Cabin_A</th>\n",
       "      <th>Cabin_B</th>\n",
       "      <th>Cabin_C</th>\n",
       "      <th>Cabin_D</th>\n",
       "      <th>Cabin_E</th>\n",
       "      <th>Cabin_F</th>\n",
       "      <th>Cabin_G</th>\n",
       "      <th>Cabin_None</th>\n",
       "      <th>Cabin_T</th>\n",
       "      <th>Embarked_C</th>\n",
       "      <th>Embarked_Missing</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Embarked_S</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>886</td>\n",
       "      <td>2</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>887</td>\n",
       "      <td>1</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>888</td>\n",
       "      <td>3</td>\n",
       "      <td>29.699118</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>23.4500</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>889</td>\n",
       "      <td>1</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>890</td>\n",
       "      <td>3</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.7500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# to make sure there is no compression in the columns\n",
    "def printall(X, max_rows=10):\n",
    "    from IPython.display import display, HTML\n",
    "    display(HTML(X.to_html(max_rows=max_rows)))\n",
    "    \n",
    "printall(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.81032547699214363"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# that is a pretty good score, but it is using a lot of the data--overfit?\n",
    "model = LogisticRegression()\n",
    "model.fit (X, y)\n",
    "model.score(X, y)\n",
    "# print \"C-stat\", roc_auc_score(y, model.predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Sex_female</th>\n",
       "      <th>Sex_male</th>\n",
       "      <th>Cabin_A</th>\n",
       "      <th>Cabin_B</th>\n",
       "      <th>...</th>\n",
       "      <th>Cabin_D</th>\n",
       "      <th>Cabin_E</th>\n",
       "      <th>Cabin_F</th>\n",
       "      <th>Cabin_G</th>\n",
       "      <th>Cabin_None</th>\n",
       "      <th>Cabin_T</th>\n",
       "      <th>Embarked_C</th>\n",
       "      <th>Embarked_Missing</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Embarked_S</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   index  Pclass   Age  SibSp  Parch     Fare  Sex_female  Sex_male  Cabin_A  \\\n",
       "0      0       3  22.0      1      0   7.2500         0.0       1.0      0.0   \n",
       "1      1       1  38.0      1      0  71.2833         1.0       0.0      0.0   \n",
       "2      2       3  26.0      0      0   7.9250         1.0       0.0      0.0   \n",
       "3      3       1  35.0      1      0  53.1000         1.0       0.0      0.0   \n",
       "4      4       3  35.0      0      0   8.0500         0.0       1.0      0.0   \n",
       "\n",
       "   Cabin_B     ...      Cabin_D  Cabin_E  Cabin_F  Cabin_G  Cabin_None  \\\n",
       "0      0.0     ...          0.0      0.0      0.0      0.0         1.0   \n",
       "1      0.0     ...          0.0      0.0      0.0      0.0         0.0   \n",
       "2      0.0     ...          0.0      0.0      0.0      0.0         1.0   \n",
       "3      0.0     ...          0.0      0.0      0.0      0.0         0.0   \n",
       "4      0.0     ...          0.0      0.0      0.0      0.0         1.0   \n",
       "\n",
       "   Cabin_T  Embarked_C  Embarked_Missing  Embarked_Q  Embarked_S  \n",
       "0      0.0         0.0               0.0         0.0         1.0  \n",
       "1      0.0         1.0               0.0         0.0         0.0  \n",
       "2      0.0         0.0               0.0         0.0         1.0  \n",
       "3      0.0         0.0               0.0         0.0         1.0  \n",
       "4      0.0         0.0               0.0         0.0         1.0  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# just checking in \n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0\n",
       "1    1\n",
       "2    1\n",
       "3    1\n",
       "4    0\n",
       "Name: Survived, dtype: int64"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# just checking in\n",
    "y.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "TEST TRAIN SPLIT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index\n",
      "Pclass\n",
      "Age\n",
      "SibSp\n",
      "Parch\n",
      "Fare\n",
      "Sex_female\n",
      "Sex_male\n",
      "Cabin_A\n",
      "Cabin_B\n",
      "Cabin_C\n",
      "Cabin_D\n",
      "Cabin_E\n",
      "Cabin_F\n",
      "Cabin_G\n",
      "Cabin_None\n",
      "Cabin_T\n",
      "Embarked_C\n",
      "Embarked_Missing\n",
      "Embarked_Q\n",
      "Embarked_S\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "21"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # lets set up a test and train set of data\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y)\n",
    "\n",
    "x_train.shape, x_test.shape\n",
    "\n",
    "for column in X.columns: \n",
    "    print column\n",
    "\n",
    "len(X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pclass=1</th>\n",
       "      <th>pclass=2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pclass=1  pclass=2\n",
       "0       0.0       0.0\n",
       "1       1.0       0.0\n",
       "2       0.0       0.0\n",
       "3       1.0       0.0\n",
       "4       0.0       0.0"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# need to pluck only two of the three choices\n",
    "pclass_dummies = pd.get_dummies(X['Pclass'])\n",
    "pclass_dummies = pclass_dummies[[1, 2]]\n",
    "pclass_dummies.columns = ['pclass=1', 'pclass=2']\n",
    "pclass_dummies.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Embarked_Missing</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Embarked_S</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Embarked_Missing  Embarked_Q  Embarked_S\n",
       "0               0.0         0.0         1.0\n",
       "1               0.0         0.0         0.0\n",
       "2               0.0         0.0         1.0\n",
       "3               0.0         0.0         1.0\n",
       "4               0.0         0.0         1.0"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# need to pluck only two of the three choices\n",
    "embarked_dummies = (X[['Embarked_Missing', 'Embarked_Q', 'Embarked_S']])\n",
    "embarked_dummies.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pclass=1</th>\n",
       "      <th>pclass=2</th>\n",
       "      <th>Sex_male</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Embarked_Missing</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Embarked_S</th>\n",
       "      <th>Child</th>\n",
       "      <th>Old Person</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pclass=1  pclass=2  Sex_male   Age  SibSp  Parch  Embarked_Missing  \\\n",
       "0       0.0       0.0       1.0  22.0      1      0               0.0   \n",
       "1       1.0       0.0       0.0  38.0      1      0               0.0   \n",
       "2       0.0       0.0       0.0  26.0      0      0               0.0   \n",
       "3       1.0       0.0       0.0  35.0      1      0               0.0   \n",
       "4       0.0       0.0       1.0  35.0      0      0               0.0   \n",
       "\n",
       "   Embarked_Q  Embarked_S  Child  Old Person  \n",
       "0         0.0         1.0      0           0  \n",
       "1         0.0         0.0      0           0  \n",
       "2         0.0         1.0      0           0  \n",
       "3         0.0         1.0      0           0  \n",
       "4         0.0         1.0      0           0  "
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analytic_df = pclass_dummies.join(X['Sex_male'])\n",
    "analytic_df = analytic_df.join(X[['Age', 'SibSp', 'Parch']])\n",
    "analytic_df = analytic_df.join(embarked_dummies)\n",
    "analytic_df['Child'] = analytic_df['Age'].apply(lambda x: 1 if x < 12 else 0)\n",
    "analytic_df['Old Person'] = analytic_df['Age'].apply(lambda x: 1 if x > 50 else 0)\n",
    "analytic_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(891, 11)\n",
      "(891, 11)\n"
     ]
    }
   ],
   "source": [
    "# shouldnt have any nulls cause I filled them earlier\n",
    "print analytic_df.shape\n",
    "analytic_df.dropna(inplace=True)\n",
    "print analytic_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.81032547699214363"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analytic_log = LogisticRegression()\n",
    "analytic_log.fit(analytic_df, y)\n",
    "analytic_log.score(analytic_df, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SelectKBest(k='all', score_func=<function f_classif at 0x11752db18>)"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lets do a kbest on train data\n",
    "kbest = SelectKBest(k='all')\n",
    "kbest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.,  1., ...,  1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  1.,  0.,  0.],\n",
       "       ..., \n",
       "       [ 0.,  0.,  0., ...,  1.,  0.,  0.],\n",
       "       [ 1.,  0.,  1., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  1., ...,  0.,  0.,  0.]])"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_kbest_all = kbest.fit_transform(analytic_df, y)\n",
    "results_kbest_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  7.91364033e+01,   7.81480472e+00,   3.72405724e+02,\n",
       "         4.35351609e+00,   1.11057220e+00,   5.96346384e+00,\n",
       "         3.22216280e+00,   1.18463440e-02,   2.20754686e+01,\n",
       "         1.13176268e+01,   4.67733759e-01])"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kbest.scores_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "logistic_regression_factory = LogisticRegression()\n",
    "rfe_factory = RFE(estimator=logistic_regression_factory, step=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.,  1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.],\n",
       "       ..., \n",
       "       [ 0.,  0.,  0.,  0.,  0.],\n",
       "       [ 1.,  0.,  1.,  0.,  0.],\n",
       "       [ 0.,  0.,  1.,  0.,  0.]])"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_of_rfe = rfe_factory.fit_transform(analytic_df, y)\n",
    "results_of_rfe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Shows three model scores. KBest, rfe, and logistic regression on the dataframe. The models were run on the full dataset and there is probably some overfitting. Can retest models on train/test data. Not sure whether to further pursue kbest and rfe for this dataset or just switch over to gridsearch..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.81032547699214363"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_kbest_all_columns = LogisticRegression()\n",
    "model_kbest_all_columns.fit(results_kbest_all, y)\n",
    "model_kbest_all_columns.score(results_kbest_all, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.78900112233445563"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_for_rfe_columns = LogisticRegression()\n",
    "model_for_rfe_columns.fit(results_of_rfe, y)\n",
    "model_for_rfe_columns.score(results_of_rfe, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.81032547699214363"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_df = LogisticRegression()\n",
    "full_df.fit(analytic_df.as_matrix(), y)\n",
    "full_df.score(analytic_df.as_matrix(), y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like my kbest and entire df have same results. Should go back and restrict k='all'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SelectKBest(k=4, score_func=<function f_classif at 0x11752db18>)"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lets redo a kbest on train data with restricted columns\n",
    "kbest = SelectKBest(k=4)\n",
    "kbest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  1.,  1.,  0.],\n",
       "       [ 1.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  1.,  0.],\n",
       "       ..., \n",
       "       [ 0.,  0.,  1.,  0.],\n",
       "       [ 1.,  1.,  0.,  0.],\n",
       "       [ 0.,  1.,  0.,  0.]])"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_of_kbest4 = kbest.fit_transform(analytic_df, y)\n",
    "results_of_kbest4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  7.91364033e+01,   7.81480472e+00,   3.72405724e+02,\n",
       "         4.35351609e+00,   1.11057220e+00,   5.96346384e+00,\n",
       "         3.22216280e+00,   1.18463440e-02,   2.20754686e+01,\n",
       "         1.13176268e+01,   4.67733759e-01])"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kbest.scores_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.79012345679012341"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# showing a lower score with less variables\n",
    "model_for_kbest4_columns = LogisticRegression()\n",
    "model_for_kbest4_columns.fit(results_of_kbest4, y)\n",
    "model_for_kbest4_columns.score(results_of_kbest4, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, moving back to logistic regression for now. Then will run it through a grid search. Going to do these models on train data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((668, 21), (668,))"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pclass=1</th>\n",
       "      <th>pclass=2</th>\n",
       "      <th>Sex_male</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Embarked_Missing</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Embarked_S</th>\n",
       "      <th>Child</th>\n",
       "      <th>Old Person</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pclass=1  pclass=2  Sex_male   Age  SibSp  Parch  Embarked_Missing  \\\n",
       "0       0.0       0.0       1.0  22.0      1      0               0.0   \n",
       "1       1.0       0.0       0.0  38.0      1      0               0.0   \n",
       "2       0.0       0.0       0.0  26.0      0      0               0.0   \n",
       "3       1.0       0.0       0.0  35.0      1      0               0.0   \n",
       "4       0.0       0.0       1.0  35.0      0      0               0.0   \n",
       "\n",
       "   Embarked_Q  Embarked_S  Child  Old Person  \n",
       "0         0.0         1.0      0           0  \n",
       "1         0.0         0.0      0           0  \n",
       "2         0.0         1.0      0           0  \n",
       "3         0.0         1.0      0           0  \n",
       "4         0.0         1.0      0           0  "
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analytic_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index\n",
      "Pclass\n",
      "Age\n",
      "SibSp\n",
      "Parch\n",
      "Fare\n",
      "Sex_female\n",
      "Sex_male\n",
      "Cabin_A\n",
      "Cabin_B\n",
      "Cabin_C\n",
      "Cabin_D\n",
      "Cabin_E\n",
      "Cabin_F\n",
      "Cabin_G\n",
      "Cabin_None\n",
      "Cabin_T\n",
      "Embarked_C\n",
      "Embarked_Missing\n",
      "Embarked_Q\n",
      "Embarked_S\n"
     ]
    }
   ],
   "source": [
    "x_train.head()\n",
    "for column in x_train.columns:\n",
    "    print column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([u'index', u'Pclass', u'Age', u'SibSp', u'Parch', u'Fare', u'Sex_female',\n",
       "       u'Sex_male', u'Cabin_A', u'Cabin_B', u'Cabin_C', u'Cabin_D', u'Cabin_E',\n",
       "       u'Cabin_F', u'Cabin_G', u'Cabin_None', u'Cabin_T', u'Embarked_C',\n",
       "       u'Embarked_Missing', u'Embarked_Q', u'Embarked_S'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this is now wrong since I re-ran it. Need to open a new notebook and start over\n",
    "x_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "messy_model_analytic = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.82185628742514971"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messy_model_analytic.fit(x_train, y_train)\n",
    "messy_model_analytic.score(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, 1, 1])"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mess_predictions = messy_model_analytic.predict(x_train)\n",
    "mess_predictions[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.30653381,  0.69346619],\n",
       "       [ 0.9533604 ,  0.0466396 ],\n",
       "       [ 0.85369504,  0.14630496],\n",
       "       ..., \n",
       "       [ 0.78160941,  0.21839059],\n",
       "       [ 0.88393685,  0.11606315],\n",
       "       [ 0.87038254,  0.12961746]])"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mess_predict_proba = messy_model_analytic.predict_proba(x_train)\n",
    "mess_predict_proba[0:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[359,  51],\n",
       "       [ 68, 190]])"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_train, mess_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.84      0.88      0.86       410\n",
      "          1       0.79      0.74      0.76       258\n",
      "\n",
      "avg / total       0.82      0.82      0.82       668\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print classification_report(y_train, mess_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x11a4a4310>"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAV4AAAD9CAYAAAD01B/uAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11a6c2ed0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.heatmap(confusion_matrix(y_train, mess_predictions), annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.75784753363228696"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messy_model_analytic.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Model did a little worse on the test data. Precision looked good with train data though. Let's see about the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.40990443,  0.59009557],\n",
       "       [ 0.60260621,  0.39739379],\n",
       "       [ 0.90746857,  0.09253143],\n",
       "       [ 0.8836736 ,  0.1163264 ],\n",
       "       [ 0.77430799,  0.22569201]])"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mess_predictions_test = messy_model_analytic.predict(x_test)\n",
    "mess_predict_proba_test = messy_model_analytic.predict_proba(x_test)\n",
    "mess_predict_proba_test[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[116,  23],\n",
       "       [ 31,  53]])"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, mess_predictions_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.79      0.83      0.81       139\n",
      "          1       0.70      0.63      0.66        84\n",
      "\n",
      "avg / total       0.75      0.76      0.76       223\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print classification_report(y_test, mess_predictions_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x11a900410>"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAV4AAAD9CAYAAAD01B/uAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nryQlZvBKUmIGryQlZvBKUmIGryQl9v/roFASGRmaDAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11a920b90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.heatmap(confusion_matrix(y_test, mess_predictions_test), annot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Looks as though the test model had a higher score in predicting death, but a lower average precision than on the train data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That is a pretty good score. It also contains quite a lot of columns. Could it be overfit? Should I move into a grid search before running my model on my test data. Also, I may pluck some x variables out for fun and see how it alters my score. Also, need confusion matrix at some point. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "xs = x_train[['Sex_female', 'Age', 'Embarked_Q', \n",
    "             'Cabin_F','Pclass']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "paired_down_model = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.81586826347305386"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# not as good of a score with my plucked x variables (but still decent)\n",
    "paired_down_model.fit(xs, y_train)\n",
    "paired_down_model.score(xs, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, 1, 1])"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = paired_down_model.predict(xs)\n",
    "predictions[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.30366303,  0.69633697],\n",
       "       [ 0.94597441,  0.05402559],\n",
       "       [ 0.89782688,  0.10217312],\n",
       "       [ 0.25805168,  0.74194832],\n",
       "       [ 0.42028899,  0.57971101]])"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_proba = paired_down_model.predict_proba(xs)\n",
    "predict_proba[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sex_female</th>\n",
       "      <th>Age</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Cabin_F</th>\n",
       "      <th>Pclass</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>612</th>\n",
       "      <td>1.0</td>\n",
       "      <td>29.699118</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Sex_female        Age  Embarked_Q  Cabin_F  Pclass\n",
       "612         1.0  29.699118         1.0      0.0       3"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xs.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The predict_proba shows the probability each variable points to whether or not someone survived. First column predicts the variables possible association to death and second life."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Going to do a confusion matrix now to check for accuracy and evaluate model fit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predicted_dead</th>\n",
       "      <th>predicted_alive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>is_dead</th>\n",
       "      <td>359</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is_alive</th>\n",
       "      <td>72</td>\n",
       "      <td>186</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          predicted_dead  predicted_alive\n",
       "is_dead              359               51\n",
       "is_alive              72              186"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confuse_matrix_1 = np.array(confusion_matrix(y_train, predictions))\n",
    "\n",
    "confusion = pd.DataFrame(confuse_matrix_1, index=['is_dead', 'is_alive'],\n",
    "                         columns=['predicted_dead', 'predicted_alive'])\n",
    "\n",
    "confusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The confusion matrix above details the predictions of my model. Its shows that it correctly predicted 356 correctly dead and 176 alive. It returned 78 false positives and 58 false negatives. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's plot the ROC curve to get a visual representation of the confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([ 0.        ,  0.00243902,  0.00243902,  0.00243902,  0.00243902,\n",
      "        0.00243902,  0.00243902,  0.00243902,  0.00487805,  0.00487805,\n",
      "        0.00487805,  0.00487805,  0.00487805,  0.00487805,  0.00487805,\n",
      "        0.00487805,  0.00487805,  0.00487805,  0.00487805,  0.00487805,\n",
      "        0.00487805,  0.00487805,  0.00487805,  0.00487805,  0.00487805,\n",
      "        0.00487805,  0.00487805,  0.00487805,  0.00487805,  0.00487805,\n",
      "        0.00487805,  0.00731707,  0.00731707,  0.0097561 ,  0.01219512,\n",
      "        0.01219512,  0.01219512,  0.01219512,  0.01219512,  0.01219512,\n",
      "        0.01219512,  0.01219512,  0.01219512,  0.01463415,  0.01463415,\n",
      "        0.02195122,  0.02195122,  0.02439024,  0.02439024,  0.02439024,\n",
      "        0.02682927,  0.02682927,  0.02682927,  0.02926829,  0.02926829,\n",
      "        0.03658537,  0.04146341,  0.04390244,  0.04390244,  0.04634146,\n",
      "        0.04634146,  0.04878049,  0.04878049,  0.05121951,  0.05121951,\n",
      "        0.05365854,  0.06341463,  0.06341463,  0.06829268,  0.07073171,\n",
      "        0.07317073,  0.07560976,  0.07804878,  0.08292683,  0.08292683,\n",
      "        0.08292683,  0.08292683,  0.08780488,  0.09268293,  0.1097561 ,\n",
      "        0.11463415,  0.11463415,  0.11707317,  0.11707317,  0.1195122 ,\n",
      "        0.1195122 ,  0.12195122,  0.12195122,  0.12439024,  0.12439024,\n",
      "        0.12682927,  0.12682927,  0.13170732,  0.13658537,  0.14146341,\n",
      "        0.14146341,  0.14634146,  0.14634146,  0.14634146,  0.14878049,\n",
      "        0.15365854,  0.15609756,  0.1804878 ,  0.18292683,  0.18536585,\n",
      "        0.18536585,  0.18780488,  0.18780488,  0.18780488,  0.19268293,\n",
      "        0.19268293,  0.19756098,  0.20243902,  0.20731707,  0.20731707,\n",
      "        0.20731707,  0.21463415,  0.21707317,  0.22195122,  0.22926829,\n",
      "        0.22926829,  0.23170732,  0.23414634,  0.23902439,  0.24146341,\n",
      "        0.24390244,  0.24878049,  0.25609756,  0.26341463,  0.26829268,\n",
      "        0.27560976,  0.27804878,  0.28292683,  0.28536585,  0.2902439 ,\n",
      "        0.29512195,  0.3097561 ,  0.31463415,  0.32195122,  0.32682927,\n",
      "        0.32926829,  0.33658537,  0.33902439,  0.34878049,  0.35609756,\n",
      "        0.37073171,  0.37560976,  0.37804878,  0.38536585,  0.3902439 ,\n",
      "        0.3902439 ,  0.39512195,  0.40731707,  0.41219512,  0.4195122 ,\n",
      "        0.42682927,  0.43414634,  0.43414634,  0.43902439,  0.44390244,\n",
      "        0.44878049,  0.44878049,  0.45121951,  0.45609756,  0.46097561,\n",
      "        0.46097561,  0.46829268,  0.46829268,  0.47317073,  0.5195122 ,\n",
      "        0.52682927,  0.53658537,  0.54390244,  0.54878049,  0.56341463,\n",
      "        0.57560976,  0.58780488,  0.60487805,  0.6097561 ,  0.63170732,\n",
      "        0.63414634,  0.65121951,  0.67804878,  0.67804878,  0.68536585,\n",
      "        0.68780488,  0.69756098,  0.7       ,  0.7097561 ,  0.72926829,\n",
      "        0.73170732,  0.73414634,  0.75609756,  0.75853659,  0.76341463,\n",
      "        0.87560976,  0.88292683,  0.88536585,  0.88536585,  0.8902439 ,\n",
      "        0.90731707,  0.91463415,  0.91707317,  0.94146341,  0.94390244,\n",
      "        0.95121951,  0.95609756,  0.96341463,  0.96585366,  0.9804878 ,\n",
      "        0.98292683,  0.98536585,  0.9902439 ,  1.        ]), array([ 0.        ,  0.        ,  0.01937984,  0.04263566,  0.0503876 ,\n",
      "        0.0620155 ,  0.06976744,  0.08914729,  0.08914729,  0.09302326,\n",
      "        0.12403101,  0.13565891,  0.14341085,  0.15116279,  0.17054264,\n",
      "        0.18217054,  0.18992248,  0.20155039,  0.20930233,  0.25581395,\n",
      "        0.26356589,  0.2751938 ,  0.28294574,  0.29457364,  0.30232558,\n",
      "        0.31007752,  0.32170543,  0.32945736,  0.3372093 ,  0.34496124,\n",
      "        0.35271318,  0.37209302,  0.37596899,  0.37596899,  0.38372093,\n",
      "        0.39922481,  0.40697674,  0.41472868,  0.42635659,  0.43410853,\n",
      "        0.44573643,  0.45348837,  0.46124031,  0.46124031,  0.47674419,\n",
      "        0.48062016,  0.48837209,  0.48837209,  0.49224806,  0.50387597,\n",
      "        0.50387597,  0.51550388,  0.51937984,  0.51937984,  0.52325581,\n",
      "        0.52325581,  0.58139535,  0.58139535,  0.58914729,  0.58914729,\n",
      "        0.59689922,  0.59689922,  0.60465116,  0.60465116,  0.60852713,\n",
      "        0.60852713,  0.61627907,  0.62015504,  0.62015504,  0.62015504,\n",
      "        0.63178295,  0.63565891,  0.64728682,  0.64728682,  0.65503876,\n",
      "        0.66666667,  0.67054264,  0.67054264,  0.6744186 ,  0.68604651,\n",
      "        0.68992248,  0.69379845,  0.70155039,  0.70930233,  0.70930233,\n",
      "        0.71317829,  0.71317829,  0.71705426,  0.71705426,  0.72093023,\n",
      "        0.72093023,  0.7248062 ,  0.7248062 ,  0.7248062 ,  0.7248062 ,\n",
      "        0.72868217,  0.72868217,  0.73643411,  0.74031008,  0.74806202,\n",
      "        0.75193798,  0.75193798,  0.76744186,  0.76744186,  0.77131783,\n",
      "        0.7751938 ,  0.7751938 ,  0.77906977,  0.78682171,  0.78682171,\n",
      "        0.79069767,  0.79457364,  0.79457364,  0.79844961,  0.81395349,\n",
      "        0.81782946,  0.81782946,  0.81782946,  0.81782946,  0.81782946,\n",
      "        0.8255814 ,  0.82945736,  0.82945736,  0.83333333,  0.83333333,\n",
      "        0.8372093 ,  0.8372093 ,  0.8372093 ,  0.8372093 ,  0.8372093 ,\n",
      "        0.8372093 ,  0.84108527,  0.84108527,  0.84108527,  0.84108527,\n",
      "        0.84108527,  0.84108527,  0.84108527,  0.84108527,  0.84108527,\n",
      "        0.84108527,  0.84108527,  0.84108527,  0.84108527,  0.84108527,\n",
      "        0.84108527,  0.84108527,  0.84108527,  0.84496124,  0.84496124,\n",
      "        0.84883721,  0.84883721,  0.84883721,  0.84883721,  0.84883721,\n",
      "        0.84883721,  0.84883721,  0.85271318,  0.85658915,  0.85658915,\n",
      "        0.86046512,  0.86821705,  0.86821705,  0.87209302,  0.87209302,\n",
      "        0.87596899,  0.87596899,  0.87984496,  0.88372093,  0.89147287,\n",
      "        0.89147287,  0.89147287,  0.89147287,  0.89147287,  0.89534884,\n",
      "        0.89534884,  0.89922481,  0.90310078,  0.90310078,  0.91085271,\n",
      "        0.91085271,  0.91085271,  0.91472868,  0.91860465,  0.91860465,\n",
      "        0.91860465,  0.92248062,  0.92248062,  0.92635659,  0.93410853,\n",
      "        0.93410853,  0.94186047,  0.94186047,  0.94186047,  0.9496124 ,\n",
      "        0.96899225,  0.97286822,  0.97286822,  0.97674419,  0.99224806,\n",
      "        0.99224806,  0.99224806,  0.99224806,  0.99224806,  0.99224806,\n",
      "        0.99224806,  0.99612403,  0.99612403,  0.99612403,  0.99612403,\n",
      "        1.        ,  1.        ,  1.        ,  1.        ]), array([ 4.00159761,  3.00159761,  2.61584548,  2.57539275,  2.525251  ,\n",
      "        2.50018013,  2.47510926,  2.45003838,  2.42496751,  2.39989664,\n",
      "        2.30715652,  2.29961314,  2.24947139,  2.22440052,  2.17425877,\n",
      "        2.1491879 ,  2.09904615,  2.07397528,  2.0489044 ,  1.84833741,\n",
      "        1.82326654,  1.77312479,  1.74805392,  1.70796245,  1.69791217,\n",
      "        1.60767896,  1.59762867,  1.58260808,  1.53246634,  1.50739546,\n",
      "        1.47227431,  1.45725371,  1.43218284,  1.40711197,  1.38204109,\n",
      "        1.35697022,  1.31437185,  1.30682847,  1.24415129,  1.23161585,\n",
      "        1.20654498,  1.17336389,  1.15640323,  1.12322215,  1.04109914,\n",
      "        1.01602827,  1.00597799,  0.9909574 ,  0.97876148,  0.96588652,\n",
      "        0.95583624,  0.94081565,  0.93076536,  0.91574477,  0.85555274,\n",
      "        0.84053215,  0.82991504,  0.80983622,  0.805411  ,  0.7903904 ,\n",
      "        0.7051275 ,  0.70264235,  0.68005663,  0.66503604,  0.63996516,\n",
      "        0.62991488,  0.61489429,  0.58982341,  0.56475254,  0.53968167,\n",
      "        0.51461079,  0.48953992,  0.46446905,  0.43939817,  0.4143273 ,\n",
      "        0.38925642,  0.37836101,  0.36418555,  0.33911468,  0.32158719,\n",
      "        0.3140438 ,  0.30114272,  0.28897293,  0.16361856,  0.13854769,\n",
      "        0.1256466 ,  0.08840594,  0.04074497,  0.03826419,  0.01567409,\n",
      "       -0.01187756, -0.02477864, -0.0620193 , -0.07492039, -0.15013301,\n",
      "       -0.17520388, -0.20027476, -0.22534563, -0.2504165 , -0.27548738,\n",
      "       -0.30055825, -0.32562913, -0.34315662, -0.3507    , -0.37577087,\n",
      "       -0.40084175, -0.42591262, -0.45098349, -0.47605437, -0.50112524,\n",
      "       -0.51329503, -0.52619612, -0.57633786, -0.60140874, -0.65155048,\n",
      "       -0.66657108, -0.72676311, -0.73929854, -0.75183398, -0.77690485,\n",
      "       -0.80197573, -0.8270466 , -0.84927105, -0.85211747, -0.87718835,\n",
      "       -0.90225922, -0.95240097, -1.00254272, -1.04263418, -1.05268447,\n",
      "       -1.06770506, -1.10282621, -1.1178468 , -1.12595701, -1.12789709,\n",
      "       -1.1632238 , -1.19305943, -1.20310971, -1.2181303 , -1.22818058,\n",
      "       -1.24320117, -1.26827205, -1.27638226, -1.29334292, -1.31841379,\n",
      "       -1.33594128, -1.34348467, -1.35353495, -1.36855554, -1.37860582,\n",
      "       -1.39362642, -1.41869729, -1.44376816, -1.46883904, -1.49390991,\n",
      "       -1.55374067, -1.56912253, -1.60424369, -1.609214  , -1.63428487,\n",
      "       -1.64433515, -1.65935574, -1.66940603, -1.68442662, -1.70258711,\n",
      "       -1.73456837, -1.76968952, -1.80287061, -1.80978099, -1.8203981 ,\n",
      "       -1.86997302, -1.93513536, -1.94518564, -1.97994553, -1.9852771 ,\n",
      "       -2.01034798, -2.03541885, -2.06048972, -2.07865022, -2.0855606 ,\n",
      "       -2.09561088, -2.11063147, -2.13570235, -2.14575263, -2.16077322,\n",
      "       -2.17330866, -2.18584409, -2.19837953, -2.21091497, -2.23598584,\n",
      "       -2.24603612, -2.26105672, -2.28612759, -2.29866303, -2.31119846,\n",
      "       -2.32872595, -2.33626934, -2.34880477, -2.36134021, -2.38641108,\n",
      "       -2.41148196, -2.43655283, -2.44908827, -2.48669458, -2.51176545,\n",
      "       -2.53683633, -2.5619072 , -2.58697807, -2.61204895, -2.68726157,\n",
      "       -2.71233244, -2.84331187, -2.86275769, -3.43938778]))\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAqcAAAI+CAYAAACBjKOPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nG/8PxNbH0jQdwhwAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11ae24850>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_score = paired_down_model.decision_function(xs)\n",
    "\n",
    "FPR = dict()\n",
    "TPR = dict()\n",
    "ROC_AUC = dict() # {}\n",
    "\n",
    "# For class 1, find the area under the curve\n",
    "\n",
    "print roc_curve(y_train, y_score)\n",
    "\n",
    "FPR[1], TPR[1], _ = roc_curve(y_train, y_score)\n",
    "ROC_AUC[1] = auc(FPR[1], TPR[1])\n",
    "\n",
    "\n",
    "# Plot of a ROC curve for class 1 (Survival)\n",
    "plt.figure(figsize=[11,9])\n",
    "plt.plot(FPR[1], TPR[1], label='ROC curve (area = %0.2f)' % ROC_AUC[1], linewidth=4)\n",
    "plt.plot([0, 1], [0, 1], 'k--', linewidth=4)\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate', fontsize=18)\n",
    "plt.ylabel('True Positive Rate', fontsize=18)\n",
    "plt.title('Variables Predicting Survival', fontsize=18)\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The greater the area under the curve shows the higher the ratio of true positives to false positives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.81586826347305386"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc = accuracy_score(y_train, predictions)\n",
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.83      0.88      0.85       410\n",
      "          1       0.78      0.72      0.75       258\n",
      "\n",
      "avg / total       0.81      0.82      0.81       668\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_train, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even though I have higher scoring models than this one I am going to go ahead and run it on my test data just for practice."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pulled the info below from notes to go over what my confusion matrix means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# The 0 and 1 on the left column indicate the two classes predicted by the model. For models with multiple classes there would be more rows and labels.\n",
    "\n",
    "# Each of the columns indicate an important metric for evaluating classification model performance.\n",
    "\n",
    "# Precision is the ability of the classifier to avoid mislabeling when the observation belongs in another class.\n",
    "\n",
    "# Precision = True Positives / (True Positives + False Positives)\n",
    "\n",
    "# A precision score of 1 indicates that the classifier never mistakenly added observations from another class. A precision score of 0 would mean that the classifier misclassified every instance of the current class.\n",
    "\n",
    "# recall is the ability of the classifier to correctly identify all observations in the current class.\n",
    "\n",
    "# Recall = True Positives / (True Positives + False Negatives)\n",
    "\n",
    "# A recall score of 1 indicates that the classifier correctly predicted (found) all observations of the current class (by implication, no false negatives, or misclassifications of the current class). A recall score of 0 alternatively means that the classifier missed all observations of the current class.\n",
    "\n",
    "# f1-score is the harmonic mean of the precision and recall. The harmonic mean is used here rather than the more conventional arithmetic mean because the harmonic mean is more appropriate for averaging rates.\n",
    "\n",
    "# F1-Score = 2 * (Precision * Recall) / (Precision + Recall)\n",
    "\n",
    "# The f1-score's best value is 1 and worst value is 0, like the precision and recall scores. It is a useful metric for taking into account both measures at once.\n",
    "\n",
    "# support is simply the number of observations of the labelled class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "xs_test = x_test[['Sex_female', 'Age', 'Embarked_Q', \n",
    "             'Cabin_F','Pclass']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using paired_down_model with test data we get: 0.744394618834\n"
     ]
    }
   ],
   "source": [
    "print 'Using paired_down_model with test data we get:', paired_down_model.score(xs_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0.7919161 <-- was score from train data. When compared to test data, test data did not have a higher score. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's not surprising that 'Sex_female', 'Age', and 'Pclass' variables did well in identifying whether or not a passenger survived. Through historical records we know that women, children, and first class passengers where given priority when boarding life boats."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will do a grid search on the train data to see what kind of scores return."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "parameters = {\n",
    "    'penalty': ['l1', 'l2'],\n",
    "    'C': [0.1, 1, 10, 5, .001]\n",
    "}\n",
    "paired_down_model = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=6, error_score='raise',\n",
       "       estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False),\n",
       "       fit_params={}, iid=True, n_jobs=1,\n",
       "       param_grid={'penalty': ['l1', 'l2'], 'C': [0.1, 1, 10, 5, 0.001]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, scoring=None, verbose=10)"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search = GridSearchCV(estimator=paired_down_model,\n",
    "                          param_grid=parameters,\n",
    "                          verbose=10,\n",
    "                          cv=6)\n",
    "grid_search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 6 folds for each of 10 candidates, totalling 60 fits\n",
      "[CV] penalty=l1, C=0.1 ...............................................\n",
      "[CV] ...................... penalty=l1, C=0.1, score=0.830357 -   0.0s\n",
      "[CV] penalty=l1, C=0.1 ...............................................\n",
      "[CV] ...................... penalty=l1, C=0.1, score=0.794643 -   0.0s\n",
      "[CV] penalty=l1, C=0.1 ...............................................\n",
      "[CV] ...................... penalty=l1, C=0.1, score=0.738739 -   0.0s\n",
      "[CV] penalty=l1, C=0.1 ...............................................\n",
      "[CV] ...................... penalty=l1, C=0.1, score=0.810811 -   0.0s\n",
      "[CV] penalty=l1, C=0.1 ...............................................\n",
      "[CV] ...................... penalty=l1, C=0.1, score=0.837838 -   0.0s\n",
      "[CV] penalty=l1, C=0.1 ...............................................\n",
      "[CV] ...................... penalty=l1, C=0.1, score=0.819820 -   0.0s\n",
      "[CV] penalty=l2, C=0.1 ...............................................\n",
      "[CV] ...................... penalty=l2, C=0.1, score=0.821429 -   0.0s\n",
      "[CV] penalty=l2, C=0.1 ...............................................\n",
      "[CV] ...................... penalty=l2, C=0.1, score=0.794643 -   0.0s\n",
      "[CV] penalty=l2, C=0.1 ...............................................\n",
      "[CV] ...................... penalty=l2, C=0.1, score=0.738739 -   0.0s\n",
      "[CV] penalty=l2, C=0.1 ...............................................\n",
      "[CV] ...................... penalty=l2, C=0.1, score=0.810811 -   0.0s\n",
      "[CV] penalty=l2, C=0.1 ...............................................\n",
      "[CV] ...................... penalty=l2, C=0.1, score=0.837838 -   0.0s\n",
      "[CV] penalty=l2, C=0.1 ...............................................\n",
      "[CV] ...................... penalty=l2, C=0.1, score=0.828829 -   0.0s\n",
      "[CV] penalty=l1, C=1 .................................................\n",
      "[CV] ........................ penalty=l1, C=1, score=0.812500 -   0.0s\n",
      "[CV] penalty=l1, C=1 .................................................\n",
      "[CV] ........................ penalty=l1, C=1, score=0.803571 -   0.0s\n",
      "[CV] penalty=l1, C=1 .................................................\n",
      "[CV] ........................ penalty=l1, C=1, score=0.747748 -   0.0s\n",
      "[CV] penalty=l1, C=1 .................................................\n",
      "[CV] ........................ penalty=l1, C=1, score=0.810811 -   0.0s\n",
      "[CV] penalty=l1, C=1 .................................................\n",
      "[CV] ........................ penalty=l1, C=1, score=0.837838 -   0.0s\n",
      "[CV] penalty=l1, C=1 .................................................\n",
      "[CV] ........................ penalty=l1, C=1, score=0.846847 -   0.0s\n",
      "[CV] penalty=l2, C=1 .................................................\n",
      "[CV] ........................ penalty=l2, C=1, score=0.821429 -   0.0s\n",
      "[CV] penalty=l2, C=1 .................................................\n",
      "[CV] ........................ penalty=l2, C=1, score=0.812500 -   0.0s\n",
      "[CV] penalty=l2, C=1 .................................................\n",
      "[CV] ........................ penalty=l2, C=1, score=0.738739 -   0.0s\n",
      "[CV] penalty=l2, C=1 .................................................\n",
      "[CV] ........................ penalty=l2, C=1, score=0.810811 -   0.0s\n",
      "[CV] penalty=l2, C=1 .................................................\n",
      "[CV] ........................ penalty=l2, C=1, score=0.837838 -   0.0s\n",
      "[CV] penalty=l2, C=1 .................................................\n",
      "[CV] ........................ penalty=l2, C=1, score=0.846847 -   0.0s\n",
      "[CV] penalty=l1, C=10 ................................................\n",
      "[CV] ....................... penalty=l1, C=10, score=0.821429 -   0.0s\n",
      "[CV] penalty=l1, C=10 ................................................\n",
      "[CV] ....................... penalty=l1, C=10, score=0.812500 -   0.0s\n",
      "[CV] penalty=l1, C=10 ................................................\n",
      "[CV] ....................... penalty=l1, C=10, score=0.747748 -   0.0s\n",
      "[CV] penalty=l1, C=10 ................................................\n",
      "[CV] ....................... penalty=l1, C=10, score=0.819820 -   0.0s\n",
      "[CV] penalty=l1, C=10 ................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 tasks       | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 tasks       | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 tasks       | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  12 tasks       | elapsed:    0.1s\n",
      "[Parallel(n_jobs=1)]: Done  17 tasks       | elapsed:    0.1s\n",
      "[Parallel(n_jobs=1)]: Done  24 tasks       | elapsed:    0.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ....................... penalty=l1, C=10, score=0.837838 -   0.0s\n",
      "[CV] penalty=l1, C=10 ................................................\n",
      "[CV] ....................... penalty=l1, C=10, score=0.855856 -   0.0s\n",
      "[CV] penalty=l2, C=10 ................................................\n",
      "[CV] ....................... penalty=l2, C=10, score=0.821429 -   0.0s\n",
      "[CV] penalty=l2, C=10 ................................................\n",
      "[CV] ....................... penalty=l2, C=10, score=0.812500 -   0.0s\n",
      "[CV] penalty=l2, C=10 ................................................\n",
      "[CV] ....................... penalty=l2, C=10, score=0.747748 -   0.0s\n",
      "[CV] penalty=l2, C=10 ................................................\n",
      "[CV] ....................... penalty=l2, C=10, score=0.819820 -   0.0s\n",
      "[CV] penalty=l2, C=10 ................................................\n",
      "[CV] ....................... penalty=l2, C=10, score=0.837838 -   0.0s\n",
      "[CV] penalty=l2, C=10 ................................................\n",
      "[CV] ....................... penalty=l2, C=10, score=0.855856 -   0.0s\n",
      "[CV] penalty=l1, C=5 .................................................\n",
      "[CV] ........................ penalty=l1, C=5, score=0.821429 -   0.0s\n",
      "[CV] penalty=l1, C=5 .................................................\n",
      "[CV] ........................ penalty=l1, C=5, score=0.812500 -   0.0s\n",
      "[CV] penalty=l1, C=5 .................................................\n",
      "[CV] ........................ penalty=l1, C=5, score=0.747748 -   0.0s\n",
      "[CV] penalty=l1, C=5 .................................................\n",
      "[CV] ........................ penalty=l1, C=5, score=0.819820 -   0.0s\n",
      "[CV] penalty=l1, C=5 .................................................\n",
      "[CV] ........................ penalty=l1, C=5, score=0.837838 -   0.0s\n",
      "[CV] penalty=l1, C=5 .................................................\n",
      "[CV] ........................ penalty=l1, C=5, score=0.855856 -   0.0s\n",
      "[CV] penalty=l2, C=5 .................................................\n",
      "[CV] ........................ penalty=l2, C=5, score=0.812500 -   0.0s\n",
      "[CV] penalty=l2, C=5 .................................................\n",
      "[CV] ........................ penalty=l2, C=5, score=0.812500 -   0.0s\n",
      "[CV] penalty=l2, C=5 .................................................\n",
      "[CV] ........................ penalty=l2, C=5, score=0.747748 -   0.0s\n",
      "[CV] penalty=l2, C=5 .................................................\n",
      "[CV] ........................ penalty=l2, C=5, score=0.819820 -   0.0s\n",
      "[CV] penalty=l2, C=5 .................................................\n",
      "[CV] ........................ penalty=l2, C=5, score=0.837838 -   0.0s\n",
      "[CV] penalty=l2, C=5 .................................................\n",
      "[CV] ........................ penalty=l2, C=5, score=0.855856 -   0.0s\n",
      "[CV] penalty=l1, C=0.001 .............................................\n",
      "[CV] .................... penalty=l1, C=0.001, score=0.616071 -   0.0s\n",
      "[CV] penalty=l1, C=0.001 .............................................\n",
      "[CV] .................... penalty=l1, C=0.001, score=0.616071 -   0.0s\n",
      "[CV] penalty=l1, C=0.001 .............................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  31 tasks       | elapsed:    0.2s\n",
      "[Parallel(n_jobs=1)]: Done  40 tasks       | elapsed:    0.3s\n",
      "[Parallel(n_jobs=1)]: Done  49 tasks       | elapsed:    0.4s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .................... penalty=l1, C=0.001, score=0.612613 -   0.0s\n",
      "[CV] penalty=l1, C=0.001 .............................................\n",
      "[CV] .................... penalty=l1, C=0.001, score=0.612613 -   0.0s\n",
      "[CV] penalty=l1, C=0.001 .............................................\n",
      "[CV] .................... penalty=l1, C=0.001, score=0.612613 -   0.0s\n",
      "[CV] penalty=l1, C=0.001 .............................................\n",
      "[CV] .................... penalty=l1, C=0.001, score=0.612613 -   0.0s\n",
      "[CV] penalty=l2, C=0.001 .............................................\n",
      "[CV] .................... penalty=l2, C=0.001, score=0.616071 -   0.0s\n",
      "[CV] penalty=l2, C=0.001 .............................................\n",
      "[CV] .................... penalty=l2, C=0.001, score=0.616071 -   0.0s\n",
      "[CV] penalty=l2, C=0.001 .............................................\n",
      "[CV] .................... penalty=l2, C=0.001, score=0.612613 -   0.0s\n",
      "[CV] penalty=l2, C=0.001 .............................................\n",
      "[CV] .................... penalty=l2, C=0.001, score=0.612613 -   0.0s\n",
      "[CV] penalty=l2, C=0.001 .............................................\n",
      "[CV] .................... penalty=l2, C=0.001, score=0.612613 -   0.0s\n",
      "[CV] penalty=l2, C=0.001 .............................................\n",
      "[CV] .................... penalty=l2, C=0.001, score=0.612613 -   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  60 tasks       | elapsed:    0.5s\n",
      "[Parallel(n_jobs=1)]: Done  60 out of  60 | elapsed:    0.5s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=6, error_score='raise',\n",
       "       estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False),\n",
       "       fit_params={}, iid=True, n_jobs=1,\n",
       "       param_grid={'penalty': ['l1', 'l2'], 'C': [0.1, 1, 10, 5, 0.001]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, scoring=None, verbose=10)"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.fit(xs, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.81586826347305386"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=10, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=10, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_estimator_.fit(xs, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.81437125748502992"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_estimator_.score(xs, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictors = grid_search.best_estimator_.predict(xs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[357,  53],\n",
       "       [ 71, 187]])"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_train, predictors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predicted_dead</th>\n",
       "      <th>predicted_alive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>is_dead</th>\n",
       "      <td>359</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is_alive</th>\n",
       "      <td>72</td>\n",
       "      <td>186</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          predicted_dead  predicted_alive\n",
       "is_dead              359               51\n",
       "is_alive              72              186"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confuse_matrix_1 = np.array(confusion_matrix(y_train, predictions))\n",
    "\n",
    "confusion = pd.DataFrame(confuse_matrix_1, index=['is_dead', 'is_alive'],\n",
    "                         columns=['predicted_dead', 'predicted_alive'])\n",
    "\n",
    "confusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.83      0.87      0.85       410\n",
      "          1       0.78      0.72      0.75       258\n",
      "\n",
      "avg / total       0.81      0.81      0.81       668\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print classification_report(y_train, predictors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x11af4dfd0>"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAV4AAAD9CAYAAAD01B/uAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAFGlJREFUeJzt3XmYHFW5x/FvdWeWJDMTVhOyAhc9aCRsyiYYNtkEBfcF\nEZWAiKxXFLgEQZagyBYR9EIQr3oF0USUiCAKSHBhUZYIniQCCQkQIUAm6yyZvn/0JHeAkJ6EnupU\n5fvh6eeZrq45c4o/fvPmrVNnklKphCQpPYVaT0CSNjQGrySlzOCVpJQZvJKUMoNXklJm8EpSyvr1\n5eBjRo11rZpe58HHJtd6CloP1bdsmrzZMdYmcx6dfc+b/nnrqk+DV5LSlCQ1y9K1YvBKyo0kyUb3\nNBuzlKQcseKVlBvFjFS8Bq+k3CgYvJKUrqzcXMvGrwdJyhErXkm5kZCNitfglZQb9nglKWVZ6fEa\nvJJyo2DwSlK6koysFzB4JeWGrQZJSpmtBklKWVaWk2WjISJJOWLFKyk3XMcrSSkrFgxeSUqVPV5J\n0mpZ8UrKDXu8kpQyH6CQpJT5AIUkpSwrN9cMXkm5YatBklJmq0GSUmarQZJSlpXlZNmYpSTliBWv\npNzw5pokpayYkVaDwSspN7KyqiEbvx4kKUeseCXlhj1eSUpZVloNBq+k3PABCklKmRWvJKWsWj3e\nEEIBuBYIQBfwRaANuKH7/fQY4wnd544DjgU6gAtjjFMrje+qBkm5UUiSXr8qOAwoxRj3BMYDFwGX\nAWfFGMcChRDCB0MIg4ETgd2Bg4AJIYS6ivN8MxcpSeuTZC3+W5MY4y2Uq1iAUcDLwE4xxnu7j90G\nvA/YBZgWY+yMMbYCM4ExleZpq0FSblSzxxtj7Aoh3AAcDnyUctCutAhoAZqBhT2OLwYGVZxn1WYp\nSTkTYzwaeBtwHdC/x0fNwCtAK+UAfu3xNTJ4JeVGkiS9fq1JCOHIEMIZ3W+XAyuAB0MIY7uPHQzc\nCzwA7BlCqA8hDAK2BaZXmqetBkm5UcVWw2TgByGEeyjn5EnAP4Hrum+ePQH8PMZYCiFMBKYBCeWb\nb+2VBjd4JeVGtTZCjzEuBT6+mo/2Xs25k4BJazO+rQZJSpkVr6TcKGTjwTWDV1J+uDuZJKXMvRok\nKWVZqXi9uSZJKbPirSBJEr7+zdPZcusRlLpKnP9fl/LkzNmrPh89Zlu+cvaXAHjxhZc485QL6Ozo\nXKufMXa/PTj2pKPo7OzklptvY/KNUykWi3zjkq8xdPgQ6ur6ce1VP+ae3/+pqtem9H3sM5+juWkg\nAMOGDuXoIz/FeRd9E4CRI4Zz3tlnUihYD60r/9hlTozdfw8olTj6Iyey867bc9Lp4zjl2LNXfX7O\nxV/htOPGM++Z5zj8Y4cwdNhg5jw9r9fjF4tFvjL+BD5x6Djalrfxw198l7vumMZe++7Oyy8v5L9O\nu4jmliZuvm2SwZtx7e3ldfWTrrlq1bGTTz+DU758PDtuP4azz7uAu++dxr5j31urKWZe7nq8IYRC\njLGrLyezPrr7d/dxz53lwBs2fAitCxev+mzUVsNZ+PJCjhr3MbZ521b88Q9/Zs7T8ygWi4y/6DRG\njBpGoVDgqksn8dBfH1n1fb9/YDL7vftDAGy9zSjmPD2XJYuXAvD3Bx9j5123545b7+J3U+8GoFAo\n0Nm5dlW01j9x5iyWLVvGcSeewooVXZz0peO44lsTSJKEjo4OXlzwEs1NTbWeZqZlJHfXHLwhhK0p\n70H5LqCze3Pgx4BTY4wzUpjfeqFUKnH+t89gnwP25D+P//qq4xttMojtdxrNhWdfztw5z3HV9RN4\n/LEZbLn1CF5a8Arnfu0SWgY1c8PNE/nQAZ/juzd8k4bGBlpamrjup5cz//kXufknt7C4dcmqMZcu\nXkpTcxPLl7cBMGBgfy695jy+c8l1qV+3qquxoYHPfebTfOiDhzF7zjMcf/Jp3PqLm3h+/nzGnXAy\nzU1NvO2t29R6mkpBpYr3OuDMGONfVx4IIewG/AB4T19ObH0z/isXs8mmG/GTW77H4fsdRVtbOwtf\nbmXO0/OY/dRcAO67535GjwkMHT6End49hjE7vgOShEKxSMugZk44+mtAueI95pOnAvDWsDUDmwes\n+jkDmgawqHURAIO32JzLv38BN/5wMrffelfKV6xq23LUSEaOGA7AqJEj2GjQIF54cQFbDBnCrb+4\nicm3/JpvXTaRC889u8JIeiNZaTVU6kQ39gxdgBjjX/pwPuud9x/xPj5//KcAaGtrp6uri65SCYC5\nc55lwMD+DBuxBQA77TKGWfEpnpw1m9/ccifHfPJUvvTZr3LH1LtpXbho1Zil7u8HeHLWbEaOGkZz\nSxP96vqx8y5jeORv/2CTzTbmez/6NpdP+B6/+sXtKV6x+sqUX93KJVd8B4B/v/ACi5cs4RsTvsmc\nZ8q/uAcMGECxmI2bQ+uram2E3ufz7BkCrxVCuAZoAH5LebPfZuAQoC3GeHylwceMGvvGg2dEY2MD\n3/j2GWy2+SYU+xW5/ur/ZcDA/vQf0MjkG6fyrt124NQzjgPg4Yemc8n536VfXT/Ovfh0thg2mIFN\nA7jpR79kyk2/ecOfsde+u/HFk48mSRKm3DSVm3/yK756zpc54NB9ePpfc8qNq1KJ4z/7VTraO9K6\n9D7z4GOTaz2Fmujo7GT8eRfw3PPzSZKEU08sr4a59MqrqK+ro7GxkXPPPpPNNt2kxjOtjfqWTd90\nGp514Jm9zpyLbp9Qs/StFLwJ5d3X96S82W8rcB8wJcZY8QLzELyqvg01eLVm1Qje8Qef1evMOf+2\ni2oWvGvs8XaH65TulySpClzHKyk3snJzzeCVlBu1vmnWWwavpNyw4pWklGUkdw1eSfmRlW0hDV5J\nuWGrQZJSlpHcNXgl5UdWKl4fDJeklFnxSsoN1/FKUspc1SBJKSsWshG89nglKWVWvJJyw1aDJKUs\nI50Gg1dSfljxSlLKMpK73lyTpLRZ8UrKjWKSjVrS4JWUG1lpNRi8knIjK5vkGLyS9BohhH7A9cCW\nQD1wYYzx192ffQr4coxxj+7344BjgY7u86ZWGj8bDRFJ6oUkSXr9quBI4MUY43uBg4GrAEIIOwKf\nX3lSCGEwcCKwO3AQMCGEUFdpcINXUm4kSe9fFfwMGN/9dQHoCCFsAlwAnNzjvF2AaTHGzhhjKzAT\nGFNpcFsNknKjWg9QxBiXAoQQmoGbKYfwJOA0oK3HqS3Awh7vFwODKo1v8ErKjWo+MhxCGAFMptxm\nmAVsA1wD9AfeHkK4DLiLcviu1Ay8Umlsg1dSblSr4u3u3d4OnBBjvKv78Hbdn40CfhpjPK37vAtC\nCPWUA3lbYHql8Q1eSblRxdVkZwIbAeNDCOcAJeDgGGPPNgMxxvkhhInANCABzooxtlca3OCVlBvV\nWscbYzwFOOUNPpsN7NHj/STK/d9eM3gl5UZWdidzOZkkpcyKV1JuZKTgNXgl5UchI3+CwuCVlBtZ\n2STHHq8kpcyKV1JuZKTgNXgl5UdWlpMZvJJyIyO5a/BKyg8rXklKWUZy1+CVlB9ZWU5m8ErKjYzk\nrsErKT+y0uP1AQpJSpkVr6TcyEjBa/BKyg83yZGklNnjlSStlhWvpNzISMFr8ErKj6y0GgxeSbmR\nkdzt2+D9833X9+XwyqgHrvxlraeg9dB7xn/hTY/hI8OSlLKM5K7BKyk/7PFKUsoykrsGr6T8SHxy\nTZLSlZWK1yfXJCllVryScsOba5KUMncnk6SUZaTgtccrSWmz4pWUHxkpeQ1eSbnhzTVJSllGctfg\nlZQf1X5yLYSwK3BxjHGfEMIOwDVABzAjxnhM9znjgGO7j18YY5xaaVxvrknKjSTp/auSEMLpwLVA\nQ/ehc4BzY4zvBRpDCO8PIQwGTgR2Bw4CJoQQ6iqNbfBKyo0kSXr96oVZwBE93v8d2CyEkADNlCvc\nXYBpMcbOGGMrMBMYU2lgg1dSblSz4o0xTgE6exyaCUwE/gG8BbgbaAEW9jhnMTCo0tgGr6TcqHLF\n+1pXAu+JMb4D+BFwGeXQbelxTjPwSqWBvLkmSb2zAFjU/fWzwB7AA8CFIYR6oD+wLTC90kAGr6Tc\n6OPlZOOAm0IIHUA7MC7GOD+EMBGYBiTAWTHG9koDGbySciMpVjd5Y4yzKVe2xBjvA/ZczTmTgElr\nM67BKyk3svLkmjfXJCllVrySciMjBa/BKyk/stJqMHgl5UZGctfglZQjGUleg1dSblR7d7K+YvBK\nyo2MFLwGr6T88OaaJKUsI7nrAxSSlDYrXkn5kZGS1+CVlBuuapCklGUleO3xSlLKrHgl5UZGWrwG\nr6T8yEqrweCVlBs+QCFJactG7npzTZLSZsUrKTcKhWzUkgavpPzIRu4avJLyIys31zLy+0GS8sOK\nV1JuZKXiNXgl5Uc2ctfglZQfPrkmSWmz1SBJ6cpI7hq8feHXt9/Jr2+/ExJoa2tn5pNPccfNP6Fp\n4AAuvfq/2XLkCD586MG1nqaqoGno5my537uY/qPbXnV88+22Ydju76RzeTv/fmQm/35k5lqPvfFb\nRzBirx0pdXXx74dnMP/hGZAkvPUDe9EwqJlCscAz0x7m5ZnPVOtyMs+baxuwww7cn8MO3B+Aiyde\nzRGHHEhHZwcnnnkOc+Y9y5YjR9R4hqqGYbtvx+bbbcOK9o5XHe/Xv4GRY3fi4WunsKKtg9FHHswr\nTz1Le+uS3g+eJGz1vl155Lpb6OrsZLujD2PBjDlsss0IOpa2MfOWP1JsrGeHcUfw0MybqnxlGZaR\nHq/rePvQ43EGT86ew+GHHMiyZcv54meP5P3771vraalKlr3Uyj9vvvN1xxs3ambJ/AWsaCsH8uJn\nX6B5+FsgSdjm0D1552cO4Z1HvZ+WkUNe9X3vPuWTq74esPlGLHuplRXtHZS6SrQ+M59BI4fw4uNP\nMufuh4BydVfq6urDK8yeJEl6/aolK94+dP1Pf8ZxR30agKFDBjN0yGCm3f9AjWelankpzqZhUNPr\nji97qZUBm29MvwGNdLV3MGiroSxbsJAhOwY6li5n1q3T6NdYzzs/eygPf38yb//EARTrivTrX8/o\nIw+mfdFSnn/oCVa0ta8ac0V7O8WGOro6VwBQrK8jfHhf5tz1YGrXq+oxePvIosVLmDN3Hjtvv12t\np6KUrWhr56nf/ZVtP7IfncuWs+S5F+lYupyN/2M4LSMH0zR0c5KkvPSpX2M9T9x4B1CueP/x43Kv\neMBbNqbYUL9qzGJ9PZ3dQVzfMpBtP7ofzz3wOC8+/lT6F7gey8VyshDCXUDDaw4nQCnGuEefzSoH\n/vbodN694w61nobS8Np/tiYJTUM2Zfr/TCUpFBj96YNY9IcHadyombbWJcz706MkxSIj9tyezuXt\nPb6xtOqrpS+8Qv9Nmik21NPV0cmgkYOZ9+dHqRvYyOhPHciTt/2ZhbOfS+f6MiQXwQucAVwLHAF0\n9v108mP23LkM32LI644nWXm0Rr1XKgfmZqO3pljXr7z6ANj+mA/S1bmCeX95jM7l7Tz/0D9X9XiL\nDXU89+ATrxrmgStufNWYT91xP6M/fRAkMP/vM+hYvIytDtiVfo31DN9rB0a8dwdKJXj8p7dTWmGv\nF8jMerKkVCqt8YQQwunArBjjlLUdfMncf615cG2QHv7B3bWegtZD7xn/hTedmnN/89teZ87wQw6q\n+PNCCLsCF8cY9wkh7ABMpFyEtgFHxRhfCCGMA44FOoALY4xTK41bcVVDjPGSdQldScqy7qLzWv6/\n3XoFcEKMcV9gCvC1EMJg4ERgd+AgYEIIoa7S2C4nk5QfyVq8KptFuc260sdjjI91f90PWA7sAkyL\nMXbGGFuBmcCYSgMbvJJyIykkvX5V0v0v/c4e7+cDhBD2AE4ALgdagIU9vm0xMKjS2AavpNxICoVe\nv9ZFCOHjwNXAITHGBUAr5fBdqRl4pdI4ruOVpF4IIRxJ+Sba3jHGleF6P3BBCKEe6A9sC0yvNJbB\nKyk/+mgdbwihAFwJzAamhBBKwD0xxvNCCBOBaZQ7x2fFGNvXMBRg8ErKkWrvwRBjnA2sfFhs0zc4\nZxIwaW3GNXgl5Uc2np8weCXlR613HestVzVIUsqseCXlRlLMRi1p8ErKj4y0GgxeSblhj1eStFpW\nvJLyIycboUtSZmSl1WDwSsoPg1eS0pWXv7kmSdlhxStJ6bLHK0lpM3glKV1Z6fH6AIUkpcyKV1J+\n2GqQpHSt6x+xTJvBKyk/7PFKklbHildSbiRJNmpJg1dSfnhzTZLS5ZNrkpS2jNxcM3gl5YYVrySl\nzeCVpJS5qkGS0uUmOZKk1bLilZQf9nglKV1JoVjrKfSKwSspN+zxSpJWy4pXUn7Y45WkdPnkmiSl\nzQcoJCllVby5FkI4A/gAUAdcDfwRuAHoAqbHGE9Y17Gz8etBknohSZJev9YkhDAW2D3GuAewNzAS\nuAw4K8Y4FiiEED64rvM0eCXlR1Lo/WvNDgSmhxB+CfwKuBXYKcZ4b/fntwH7r+s0bTVIyo0q3lzb\njHKVeyiwNeXw7ZnWi4BB6zq4wSspP6p3c20B8ESMsROYEUJYDgzv8Xkz8Mq6Dm6rQZJebxpwEEAI\nYSgwEPh9d+8X4GDg3jf43oqseCXlRrUeGY4xTg0h7BVCuB9IgOOBp4HrQgh1wBPAz9d1fINXUn5U\n8QGKGOMZqzm8dzXGNngl5UZWdidLSqVSrecgSRsUb65JUsoMXklKmcErSSkzeCUpZQavJKXM4JWk\nlLmOt4+FEBLKe3luDywHjokxPlnbWWl9EELYFbg4xrhPreeidFnx9r3DgYbufT3PpLynpzZwIYTT\ngWuBhlrPRekzePvensBvAWKMfwXeVdvpaD0xCzii1pNQbRi8fa8FWNjjfWcIwf/vG7gY4xSgs9bz\nUG0YAH2vlfLenSsVYoxdtZqMpNozePvefcAhACGE3YDHajsdrWey8ffIVVWuauh7U4D3hRDu637/\nuVpORusdd6naALk7mSSlzFaDJKXM4JWklBm8kpQyg1eSUmbwSlLKDF5JSpnBK0kpM3glKWX/B1Fr\nynQyA1K4AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11af4dc10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.heatmap(confusion_matrix(y_train, predictors), annot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Before I accept this model I want to go back and restrain my x variables to be old age, male, first class, and missing embarked location."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pclass=1</th>\n",
       "      <th>pclass=2</th>\n",
       "      <th>Sex_male</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Embarked_Missing</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Embarked_S</th>\n",
       "      <th>Child</th>\n",
       "      <th>Old Person</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pclass=1  pclass=2  Sex_male   Age  SibSp  Parch  Embarked_Missing  \\\n",
       "0       0.0       0.0       1.0  22.0      1      0               0.0   \n",
       "\n",
       "   Embarked_Q  Embarked_S  Child  Old Person  \n",
       "0         0.0         1.0      0           0  "
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analytic_df.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Need to make a train test split on this dataframe. Then I will run a logistic regression on my plucked out x variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_plucked = analytic_df[['pclass=1', 'Sex_male', 'Old Person', 'Embarked_Missing']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(data_plucked, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((668, 4), (668,))"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((223, 4), (223,))"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pluck_model = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pluck_model.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.78443113772455086"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pluck_model.score(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pluck_model_lasso = LogisticRegression(penalty='l1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.78443113772455086"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pluck_model_lasso.fit(x_train, y_train)\n",
    "pluck_model_lasso.score(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 0, 0, 0])"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict = pluck_model.predict(x_train)\n",
    "predict[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.35777567,  0.64222433],\n",
       "       [ 0.35777567,  0.64222433],\n",
       "       [ 0.86806331,  0.13193669],\n",
       "       ..., \n",
       "       [ 0.86806331,  0.13193669],\n",
       "       [ 0.35777567,  0.64222433],\n",
       "       [ 0.35777567,  0.64222433]])"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_proba = pluck_model.predict_proba(x_train)\n",
    "predict_proba[0:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before modeling on my test data, let's do a confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[348,  65],\n",
       "       [ 79, 176]])"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_train, predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predicted_dead</th>\n",
       "      <th>predicted_alive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>is_dead</th>\n",
       "      <td>348</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is_alive</th>\n",
       "      <td>79</td>\n",
       "      <td>176</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          predicted_dead  predicted_alive\n",
       "is_dead              348               65\n",
       "is_alive              79              176"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confuse_matrix_org = np.array(confusion_matrix(y_train, predict))\n",
    "\n",
    "confusion_org = pd.DataFrame(confuse_matrix_org, index=['is_dead', 'is_alive'],\n",
    "                         columns=['predicted_dead', 'predicted_alive'])\n",
    "\n",
    "confusion_org"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above confusion matrix shows that there were 340 true negatives predicted by the model, 64 false negatives, 85 false positives, and 179 true positives. So, predicting that 64 people survived when they were in fact dead is not too shabby for my model. Let's check precision with a classification report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.81      0.84      0.83       413\n",
      "          1       0.73      0.69      0.71       255\n",
      "\n",
      "avg / total       0.78      0.78      0.78       668\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print classification_report(y_train, predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overall good scores for predicting death. On the other hand it may not be the best model if you are a glass half full kind of person."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x11b3b8310>"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAV4AAAD9CAYAAAD01B/uAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11af78510>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.heatmap(confusion_matrix(y_train,predict), annot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's run test data through this model now and see what happens to the scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.79372197309417036"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pluck_model.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After passing the test data through the model it shows a higher score. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusion:\n",
    "\n",
    "So, let's recap: I have made three different models. All vary in their predictive power. Best score has been with messy_model_analytic and plucked_model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = pd.read_csv('../downloads/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "passenger_id = pd.read_csv('../downloads/test.csv')\n",
    "passenger_id = passenger_id['PassengerId']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X['Age'].fillna(X.Age.mean(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X['Fare'].fillna(X.Fare.mean(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X.drop(['Name', 'Ticket', 'PassengerId'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def clean_cabin(x):\n",
    "    try:\n",
    "        return x[0]\n",
    "    except TypeError:\n",
    "        return 'None'\n",
    "    \n",
    "X['Cabin'] = X.Cabin.apply(clean_cabin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "categorical_variables = ['Sex', 'Cabin', 'Embarked']\n",
    "\n",
    "for variable in categorical_variables:\n",
    "    X[variable].fillna('Missing', inplace=True)\n",
    "    dummies = pd.get_dummies(X[variable], prefix=variable)\n",
    "    X = pd.concat([X, dummies], axis=1)\n",
    "    X.drop([variable], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Sex_female</th>\n",
       "      <th>Sex_male</th>\n",
       "      <th>Cabin_A</th>\n",
       "      <th>Cabin_B</th>\n",
       "      <th>Cabin_C</th>\n",
       "      <th>Cabin_D</th>\n",
       "      <th>Cabin_E</th>\n",
       "      <th>Cabin_F</th>\n",
       "      <th>Cabin_G</th>\n",
       "      <th>Cabin_None</th>\n",
       "      <th>Embarked_C</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Embarked_S</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>34.50000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.8292</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>47.00000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.0000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>62.00000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9.6875</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>27.00000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.6625</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>22.00000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>12.2875</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>413</th>\n",
       "      <td>3</td>\n",
       "      <td>30.27259</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>414</th>\n",
       "      <td>1</td>\n",
       "      <td>39.00000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>108.9000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>415</th>\n",
       "      <td>3</td>\n",
       "      <td>38.50000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416</th>\n",
       "      <td>3</td>\n",
       "      <td>30.27259</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>417</th>\n",
       "      <td>3</td>\n",
       "      <td>30.27259</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>22.3583</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def printall(X, max_rows=10):\n",
    "    from IPython.display import display, HTML\n",
    "    display(HTML(X.to_html(max_rows=max_rows)))\n",
    "    \n",
    "printall(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pclass=1</th>\n",
       "      <th>pclass=2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pclass=1  pclass=2\n",
       "0       0.0       0.0\n",
       "1       0.0       0.0\n",
       "2       0.0       1.0\n",
       "3       0.0       0.0\n",
       "4       0.0       0.0"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pclass_dummies = pd.get_dummies(X['Pclass'])\n",
    "pclass_dummies = pclass_dummies[[1, 2]]\n",
    "pclass_dummies.columns = ['pclass=1', 'pclass=2']\n",
    "pclass_dummies.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Driz/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Embarked_Missing</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Embarked_S</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Embarked_Missing  Embarked_Q  Embarked_S\n",
       "0                 0         1.0         0.0\n",
       "1                 0         0.0         1.0\n",
       "2                 0         1.0         0.0\n",
       "3                 0         0.0         1.0\n",
       "4                 0         0.0         1.0"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embarked_dummies = (X[[ 'Embarked_Q', 'Embarked_S']])\n",
    "embarked_dummies['Embarked_Missing'] = 0\n",
    "cols = embarked_dummies.columns.tolist()[-1:] + embarked_dummies.columns.tolist()[:-1]\n",
    "embarked_dummies = embarked_dummies[cols]\n",
    "embarked_dummies.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pclass=1</th>\n",
       "      <th>pclass=2</th>\n",
       "      <th>Sex_male</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Embarked_Missing</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Embarked_S</th>\n",
       "      <th>Child</th>\n",
       "      <th>Old Person</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>34.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pclass=1  pclass=2  Sex_male   Age  SibSp  Parch  Embarked_Missing  \\\n",
       "0       0.0       0.0       1.0  34.5      0      0                 0   \n",
       "1       0.0       0.0       0.0  47.0      1      0                 0   \n",
       "2       0.0       1.0       1.0  62.0      0      0                 0   \n",
       "3       0.0       0.0       1.0  27.0      0      0                 0   \n",
       "4       0.0       0.0       0.0  22.0      1      1                 0   \n",
       "\n",
       "   Embarked_Q  Embarked_S  Child  Old Person  \n",
       "0         1.0         0.0      0           0  \n",
       "1         0.0         1.0      0           0  \n",
       "2         1.0         0.0      0           1  \n",
       "3         0.0         1.0      0           0  \n",
       "4         0.0         1.0      0           0  "
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analytic_df = pclass_dummies.join(X['Sex_male'])\n",
    "analytic_df = analytic_df.join(X[['Age', 'SibSp', 'Parch']])\n",
    "analytic_df = analytic_df.join(embarked_dummies)\n",
    "analytic_df['Child'] = analytic_df['Age'].apply(lambda x: 1 if x < 12 else 0)\n",
    "analytic_df['Old Person'] = analytic_df['Age'].apply(lambda x: 1 if x > 50 else 0)\n",
    "analytic_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Sex_female</th>\n",
       "      <th>Sex_male</th>\n",
       "      <th>Cabin_A</th>\n",
       "      <th>Cabin_B</th>\n",
       "      <th>Cabin_C</th>\n",
       "      <th>Cabin_D</th>\n",
       "      <th>Cabin_E</th>\n",
       "      <th>Cabin_F</th>\n",
       "      <th>Cabin_G</th>\n",
       "      <th>Cabin_None</th>\n",
       "      <th>Embarked_C</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Embarked_S</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>34.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.8292</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>47.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.0000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9.6875</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.6625</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>12.2875</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pclass   Age  SibSp  Parch     Fare  Sex_female  Sex_male  Cabin_A  \\\n",
       "0       3  34.5      0      0   7.8292         0.0       1.0      0.0   \n",
       "1       3  47.0      1      0   7.0000         1.0       0.0      0.0   \n",
       "2       2  62.0      0      0   9.6875         0.0       1.0      0.0   \n",
       "3       3  27.0      0      0   8.6625         0.0       1.0      0.0   \n",
       "4       3  22.0      1      1  12.2875         1.0       0.0      0.0   \n",
       "\n",
       "   Cabin_B  Cabin_C  Cabin_D  Cabin_E  Cabin_F  Cabin_G  Cabin_None  \\\n",
       "0      0.0      0.0      0.0      0.0      0.0      0.0         1.0   \n",
       "1      0.0      0.0      0.0      0.0      0.0      0.0         1.0   \n",
       "2      0.0      0.0      0.0      0.0      0.0      0.0         1.0   \n",
       "3      0.0      0.0      0.0      0.0      0.0      0.0         1.0   \n",
       "4      0.0      0.0      0.0      0.0      0.0      0.0         1.0   \n",
       "\n",
       "   Embarked_C  Embarked_Q  Embarked_S  \n",
       "0         0.0         1.0         0.0  \n",
       "1         0.0         0.0         1.0  \n",
       "2         0.0         1.0         0.0  \n",
       "3         0.0         0.0         1.0  \n",
       "4         0.0         0.0         1.0  "
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pclass\n",
      "Age\n",
      "SibSp\n",
      "Parch\n",
      "Fare\n",
      "Sex_female\n",
      "Sex_male\n",
      "Cabin_A\n",
      "Cabin_B\n",
      "Cabin_C\n",
      "Cabin_D\n",
      "Cabin_E\n",
      "Cabin_F\n",
      "Cabin_G\n",
      "Cabin_None\n",
      "Embarked_C\n",
      "Embarked_Q\n",
      "Embarked_S\n"
     ]
    }
   ],
   "source": [
    "for column in X.columns:\n",
    "    print column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "index\tPclass\tAge\tSibSp\tParch\tFare\tSex_female\tSex_male\tCabin_A\tCabin_B\tCabin_C\tCabin_D\tCabin_E\tCabin_F\tCabin_G\tCabin_None\tCabin_T\tEmbarked_C\tEmbarked_Missing\tEmbarked_Q\tEmbarked_S"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "index\n",
    "Pclass\n",
    "Age\n",
    "SibSp\n",
    "Parch\n",
    "Fare\n",
    "Sex_female\n",
    "Sex_male\n",
    "Cabin_A\n",
    "Cabin_B\n",
    "Cabin_C\n",
    "Cabin_D\n",
    "Cabin_E\n",
    "Cabin_F\n",
    "Cabin_G\n",
    "Cabin_None\n",
    "Cabin_T\n",
    "Embarked_C\n",
    "Embarked_Missing\n",
    "Embarked_Q\n",
    "Embarked_S\n",
    "\n",
    "Pclass\n",
    "Age\n",
    "SibSp\n",
    "Parch\n",
    "Fare\n",
    "Sex_female\n",
    "Sex_male\n",
    "Cabin_A\n",
    "Cabin_B\n",
    "Cabin_C\n",
    "Cabin_D\n",
    "Cabin_E\n",
    "Cabin_F\n",
    "Cabin_G\n",
    "Cabin_None\n",
    "Embarked_C\n",
    "Embarked_Q\n",
    "Embarked_S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X['index'] = 0\n",
    "X['Cabin_T'] = 0\n",
    "X['Embarked_Missing'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Sex_female</th>\n",
       "      <th>Sex_male</th>\n",
       "      <th>Cabin_A</th>\n",
       "      <th>Cabin_B</th>\n",
       "      <th>...</th>\n",
       "      <th>Cabin_D</th>\n",
       "      <th>Cabin_E</th>\n",
       "      <th>Cabin_F</th>\n",
       "      <th>Cabin_G</th>\n",
       "      <th>Cabin_None</th>\n",
       "      <th>Cabin_T</th>\n",
       "      <th>Embarked_C</th>\n",
       "      <th>Embarked_Missing</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Embarked_S</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>34.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.8292</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>47.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.0000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9.6875</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.6625</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>12.2875</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   index  Pclass   Age  SibSp  Parch     Fare  Sex_female  Sex_male  Cabin_A  \\\n",
       "0      0       3  34.5      0      0   7.8292         0.0       1.0      0.0   \n",
       "1      0       3  47.0      1      0   7.0000         1.0       0.0      0.0   \n",
       "2      0       2  62.0      0      0   9.6875         0.0       1.0      0.0   \n",
       "3      0       3  27.0      0      0   8.6625         0.0       1.0      0.0   \n",
       "4      0       3  22.0      1      1  12.2875         1.0       0.0      0.0   \n",
       "\n",
       "   Cabin_B     ...      Cabin_D  Cabin_E  Cabin_F  Cabin_G  Cabin_None  \\\n",
       "0      0.0     ...          0.0      0.0      0.0      0.0         1.0   \n",
       "1      0.0     ...          0.0      0.0      0.0      0.0         1.0   \n",
       "2      0.0     ...          0.0      0.0      0.0      0.0         1.0   \n",
       "3      0.0     ...          0.0      0.0      0.0      0.0         1.0   \n",
       "4      0.0     ...          0.0      0.0      0.0      0.0         1.0   \n",
       "\n",
       "   Cabin_T  Embarked_C  Embarked_Missing  Embarked_Q  Embarked_S  \n",
       "0        0         0.0                 0         1.0         0.0  \n",
       "1        0         0.0                 0         0.0         1.0  \n",
       "2        0         0.0                 0         1.0         0.0  \n",
       "3        0         0.0                 0         0.0         1.0  \n",
       "4        0         0.0                 0         0.0         1.0  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols = ['index',\n",
    "'Pclass',\n",
    "'Age',\n",
    "'SibSp',\n",
    "'Parch',\n",
    "'Fare',\n",
    "'Sex_female',\n",
    "'Sex_male',\n",
    "'Cabin_A',\n",
    "'Cabin_B',\n",
    "'Cabin_C',\n",
    "'Cabin_D',\n",
    "'Cabin_E',\n",
    "'Cabin_F',\n",
    "'Cabin_G',\n",
    "'Cabin_None',\n",
    "'Cabin_T',\n",
    "'Embarked_C',\n",
    "'Embarked_Missing',\n",
    "'Embarked_Q',\n",
    "'Embarked_S']\n",
    "\n",
    "X = X[cols]\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictions = messy_model_analytic.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "passenger_id = pd.DataFrame(passenger_id)\n",
    "passenger_id['Survived'] = predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "passenger_id.to_csv('submission.csv', header=True, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
