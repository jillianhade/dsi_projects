{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import all the things!\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.cross_validation import KFold\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.grid_search import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = pd.read_csv('../titanic.csv')\n",
    "y = X.pop('Survived')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Driz/anaconda2/lib/python2.7/site-packages/numpy/lib/function_base.py:3834: RuntimeWarning: Invalid value encountered in percentile\n",
      "  RuntimeWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>714.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>445.000000</td>\n",
       "      <td>446.000000</td>\n",
       "      <td>2.308642</td>\n",
       "      <td>29.699118</td>\n",
       "      <td>0.523008</td>\n",
       "      <td>0.381594</td>\n",
       "      <td>32.204208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>257.353842</td>\n",
       "      <td>257.353842</td>\n",
       "      <td>0.836071</td>\n",
       "      <td>14.526497</td>\n",
       "      <td>1.102743</td>\n",
       "      <td>0.806057</td>\n",
       "      <td>49.693429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>222.500000</td>\n",
       "      <td>223.500000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.910400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>445.000000</td>\n",
       "      <td>446.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.454200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>667.500000</td>\n",
       "      <td>668.500000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>890.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>512.329200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            index  PassengerId      Pclass         Age       SibSp  \\\n",
       "count  891.000000   891.000000  891.000000  714.000000  891.000000   \n",
       "mean   445.000000   446.000000    2.308642   29.699118    0.523008   \n",
       "std    257.353842   257.353842    0.836071   14.526497    1.102743   \n",
       "min      0.000000     1.000000    1.000000    0.420000    0.000000   \n",
       "25%    222.500000   223.500000    2.000000         NaN    0.000000   \n",
       "50%    445.000000   446.000000    3.000000         NaN    0.000000   \n",
       "75%    667.500000   668.500000    3.000000         NaN    1.000000   \n",
       "max    890.000000   891.000000    3.000000   80.000000    8.000000   \n",
       "\n",
       "            Parch        Fare  \n",
       "count  891.000000  891.000000  \n",
       "mean     0.381594   32.204208  \n",
       "std      0.806057   49.693429  \n",
       "min      0.000000    0.000000  \n",
       "25%      0.000000    7.910400  \n",
       "50%      0.000000   14.454200  \n",
       "75%      0.000000   31.000000  \n",
       "max      6.000000  512.329200  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.describe()\n",
    "# age has missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>445.000000</td>\n",
       "      <td>446.000000</td>\n",
       "      <td>2.308642</td>\n",
       "      <td>29.699118</td>\n",
       "      <td>0.523008</td>\n",
       "      <td>0.381594</td>\n",
       "      <td>32.204208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>257.353842</td>\n",
       "      <td>257.353842</td>\n",
       "      <td>0.836071</td>\n",
       "      <td>13.002015</td>\n",
       "      <td>1.102743</td>\n",
       "      <td>0.806057</td>\n",
       "      <td>49.693429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>222.500000</td>\n",
       "      <td>223.500000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.910400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>445.000000</td>\n",
       "      <td>446.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>29.699118</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.454200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>667.500000</td>\n",
       "      <td>668.500000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>890.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>512.329200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            index  PassengerId      Pclass         Age       SibSp  \\\n",
       "count  891.000000   891.000000  891.000000  891.000000  891.000000   \n",
       "mean   445.000000   446.000000    2.308642   29.699118    0.523008   \n",
       "std    257.353842   257.353842    0.836071   13.002015    1.102743   \n",
       "min      0.000000     1.000000    1.000000    0.420000    0.000000   \n",
       "25%    222.500000   223.500000    2.000000   22.000000    0.000000   \n",
       "50%    445.000000   446.000000    3.000000   29.699118    0.000000   \n",
       "75%    667.500000   668.500000    3.000000   35.000000    1.000000   \n",
       "max    890.000000   891.000000    3.000000   80.000000    8.000000   \n",
       "\n",
       "            Parch        Fare  \n",
       "count  891.000000  891.000000  \n",
       "mean     0.381594   32.204208  \n",
       "std      0.806057   49.693429  \n",
       "min      0.000000    0.000000  \n",
       "25%      0.000000    7.910400  \n",
       "50%      0.000000   14.454200  \n",
       "75%      0.000000   31.000000  \n",
       "max      6.000000  512.329200  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# impute age with mean\n",
    "X['Age'].fillna(X.Age.mean(), inplace=True)\n",
    "\n",
    "# confirm\n",
    "X.describe()\n",
    "\n",
    "# ignoring categorical variables for right now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index  PassengerId  Pclass   Age  SibSp  Parch     Fare\n",
       "0      0            1       3  22.0      1      0   7.2500\n",
       "1      1            2       1  38.0      1      0  71.2833\n",
       "2      2            3       3  26.0      0      0   7.9250\n",
       "3      3            4       1  35.0      1      0  53.1000\n",
       "4      4            5       3  35.0      0      0   8.0500"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# return just numeric variables ignoring 'object' datatypes\n",
    "numeric_variables = list(X.dtypes[X.dtypes != 'object'].index)\n",
    "X[numeric_variables].head()\n",
    "# passenger id seems ignorable "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LogisticRegression()\n",
    "model.fit(X[numeric_variables], y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.70258136924803594"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# not shabby for a quick model to get going, but I think I can get a better score\n",
    "model.score(X[numeric_variables], y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method LogisticRegression.predict_proba of LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# do predictions to get to confusion matrix\n",
    "# not sure what I was going with this\n",
    "model.predict_proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# function to show descriptive stats on categorical variables\n",
    "def describe_categorical(X):\n",
    "    from IPython.display import display, HTML\n",
    "    display(HTML(X[X.columns[X.dtypes == 'object']].describe().to_html()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>891</td>\n",
       "      <td>891</td>\n",
       "      <td>891</td>\n",
       "      <td>204</td>\n",
       "      <td>889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>891</td>\n",
       "      <td>2</td>\n",
       "      <td>681</td>\n",
       "      <td>147</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>Graham, Mr. George Edward</td>\n",
       "      <td>male</td>\n",
       "      <td>CA. 2343</td>\n",
       "      <td>C23 C25 C27</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>1</td>\n",
       "      <td>577</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>644</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "describe_categorical(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# drop variables I dont want in this\n",
    "X.drop(['Name', 'Ticket', 'PassengerId'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# change cabin variable to be first letter\n",
    "def clean_cabin(x):\n",
    "    try:\n",
    "        return x[0]\n",
    "    except TypeError:\n",
    "        return 'None'\n",
    "    \n",
    "X['Cabin'] = X.Cabin.apply(clean_cabin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    None\n",
       "1       C\n",
       "2    None\n",
       "3       C\n",
       "4    None\n",
       "Name: Cabin, dtype: object"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# if data is missing returns none\n",
    "X.Cabin.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "categorical_variables = ['Sex', 'Cabin', 'Embarked']\n",
    "\n",
    "for variable in categorical_variables:\n",
    "    X[variable].fillna('Missing', inplace=True)\n",
    "    dummies = pd.get_dummies(X[variable], prefix=variable)\n",
    "    X = pd.concat([X, dummies], axis=1)\n",
    "    X.drop([variable], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Sex_female</th>\n",
       "      <th>Sex_male</th>\n",
       "      <th>Cabin_A</th>\n",
       "      <th>Cabin_B</th>\n",
       "      <th>Cabin_C</th>\n",
       "      <th>Cabin_D</th>\n",
       "      <th>Cabin_E</th>\n",
       "      <th>Cabin_F</th>\n",
       "      <th>Cabin_G</th>\n",
       "      <th>Cabin_None</th>\n",
       "      <th>Cabin_T</th>\n",
       "      <th>Embarked_C</th>\n",
       "      <th>Embarked_Missing</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Embarked_S</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>886</td>\n",
       "      <td>2</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>887</td>\n",
       "      <td>1</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>888</td>\n",
       "      <td>3</td>\n",
       "      <td>29.699118</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>23.4500</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>889</td>\n",
       "      <td>1</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>890</td>\n",
       "      <td>3</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.7500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# to make sure there is no compression in the columns\n",
    "def printall(X, max_rows=10):\n",
    "    from IPython.display import display, HTML\n",
    "    display(HTML(X.to_html(max_rows=max_rows)))\n",
    "    \n",
    "printall(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.81032547699214363"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# that is a pretty good score, but it is using a lot of the data--overfit?\n",
    "model = LogisticRegression()\n",
    "model.fit (X, y)\n",
    "model.score(X, y)\n",
    "# print \"C-stat\", roc_auc_score(y, model.predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Sex_female</th>\n",
       "      <th>Sex_male</th>\n",
       "      <th>Cabin_A</th>\n",
       "      <th>Cabin_B</th>\n",
       "      <th>...</th>\n",
       "      <th>Cabin_D</th>\n",
       "      <th>Cabin_E</th>\n",
       "      <th>Cabin_F</th>\n",
       "      <th>Cabin_G</th>\n",
       "      <th>Cabin_None</th>\n",
       "      <th>Cabin_T</th>\n",
       "      <th>Embarked_C</th>\n",
       "      <th>Embarked_Missing</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Embarked_S</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   index  Pclass   Age  SibSp  Parch     Fare  Sex_female  Sex_male  Cabin_A  \\\n",
       "0      0       3  22.0      1      0   7.2500         0.0       1.0      0.0   \n",
       "1      1       1  38.0      1      0  71.2833         1.0       0.0      0.0   \n",
       "2      2       3  26.0      0      0   7.9250         1.0       0.0      0.0   \n",
       "3      3       1  35.0      1      0  53.1000         1.0       0.0      0.0   \n",
       "4      4       3  35.0      0      0   8.0500         0.0       1.0      0.0   \n",
       "\n",
       "   Cabin_B     ...      Cabin_D  Cabin_E  Cabin_F  Cabin_G  Cabin_None  \\\n",
       "0      0.0     ...          0.0      0.0      0.0      0.0         1.0   \n",
       "1      0.0     ...          0.0      0.0      0.0      0.0         0.0   \n",
       "2      0.0     ...          0.0      0.0      0.0      0.0         1.0   \n",
       "3      0.0     ...          0.0      0.0      0.0      0.0         0.0   \n",
       "4      0.0     ...          0.0      0.0      0.0      0.0         1.0   \n",
       "\n",
       "   Cabin_T  Embarked_C  Embarked_Missing  Embarked_Q  Embarked_S  \n",
       "0      0.0         0.0               0.0         0.0         1.0  \n",
       "1      0.0         1.0               0.0         0.0         0.0  \n",
       "2      0.0         0.0               0.0         0.0         1.0  \n",
       "3      0.0         0.0               0.0         0.0         1.0  \n",
       "4      0.0         0.0               0.0         0.0         1.0  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# just checking in \n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0\n",
       "1    1\n",
       "2    1\n",
       "3    1\n",
       "4    0\n",
       "Name: Survived, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# just checking in\n",
    "y.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "TEST TRAIN SPLIT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((668, 21), (223, 21))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lets set up a test and train set of data\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y)\n",
    "\n",
    "x_train.shape, x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pclass=1</th>\n",
       "      <th>pclass=2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pclass=1  pclass=2\n",
       "0       0.0       0.0\n",
       "1       1.0       0.0\n",
       "2       0.0       0.0\n",
       "3       1.0       0.0\n",
       "4       0.0       0.0"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# need to pluck only two of the three choices\n",
    "pclass_dummies = pd.get_dummies(X['Pclass'])\n",
    "pclass_dummies = pclass_dummies[[1, 2]]\n",
    "pclass_dummies.columns = ['pclass=1', 'pclass=2']\n",
    "pclass_dummies.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Embarked_Missing</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Embarked_S</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Embarked_Missing  Embarked_Q  Embarked_S\n",
       "0               0.0         0.0         1.0\n",
       "1               0.0         0.0         0.0\n",
       "2               0.0         0.0         1.0\n",
       "3               0.0         0.0         1.0\n",
       "4               0.0         0.0         1.0"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# need to pluck only two of the three choices\n",
    "embarked_dummies = (X[['Embarked_Missing', 'Embarked_Q', 'Embarked_S']])\n",
    "embarked_dummies.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pclass=1</th>\n",
       "      <th>pclass=2</th>\n",
       "      <th>Sex_male</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Embarked_Missing</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Embarked_S</th>\n",
       "      <th>Child</th>\n",
       "      <th>Old Person</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pclass=1  pclass=2  Sex_male   Age  SibSp  Parch  Embarked_Missing  \\\n",
       "0       0.0       0.0       1.0  22.0      1      0               0.0   \n",
       "1       1.0       0.0       0.0  38.0      1      0               0.0   \n",
       "2       0.0       0.0       0.0  26.0      0      0               0.0   \n",
       "3       1.0       0.0       0.0  35.0      1      0               0.0   \n",
       "4       0.0       0.0       1.0  35.0      0      0               0.0   \n",
       "\n",
       "   Embarked_Q  Embarked_S  Child  Old Person  \n",
       "0         0.0         1.0      0           0  \n",
       "1         0.0         0.0      0           0  \n",
       "2         0.0         1.0      0           0  \n",
       "3         0.0         1.0      0           0  \n",
       "4         0.0         1.0      0           0  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analytic_df = pclass_dummies.join(X['Sex_male'])\n",
    "analytic_df = analytic_df.join(X[['Age', 'SibSp', 'Parch']])\n",
    "analytic_df = analytic_df.join(embarked_dummies)\n",
    "analytic_df['Child'] = analytic_df['Age'].apply(lambda x: 1 if x < 12 else 0)\n",
    "analytic_df['Old Person'] = analytic_df['Age'].apply(lambda x: 1 if x > 50 else 0)\n",
    "analytic_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(891, 11)\n",
      "(891, 11)\n"
     ]
    }
   ],
   "source": [
    "# shouldnt have any nulls cause I filled them earlier\n",
    "print analytic_df.shape\n",
    "analytic_df.dropna(inplace=True)\n",
    "print analytic_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.81032547699214363"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analytic_log = LogisticRegression()\n",
    "analytic_log.fit(analytic_df, y)\n",
    "analytic_log.score(analytic_df, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SelectKBest(k='all', score_func=<function f_classif at 0x117722b90>)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lets do a kbest on train data\n",
    "kbest = SelectKBest(k='all')\n",
    "kbest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.,  1., ...,  1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  1.,  0.,  0.],\n",
       "       ..., \n",
       "       [ 0.,  0.,  0., ...,  1.,  0.,  0.],\n",
       "       [ 1.,  0.,  1., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  1., ...,  0.,  0.,  0.]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_kbest_all = kbest.fit_transform(analytic_df, y)\n",
    "results_kbest_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  7.91364033e+01,   7.81480472e+00,   3.72405724e+02,\n",
       "         4.35351609e+00,   1.11057220e+00,   5.96346384e+00,\n",
       "         3.22216280e+00,   1.18463440e-02,   2.20754686e+01,\n",
       "         1.13176268e+01,   4.67733759e-01])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kbest.scores_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "logistic_regression_factory = LogisticRegression()\n",
    "rfe_factory = RFE(estimator=logistic_regression_factory, step=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.,  1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.],\n",
       "       ..., \n",
       "       [ 0.,  0.,  0.,  0.,  0.],\n",
       "       [ 1.,  0.,  1.,  0.,  0.],\n",
       "       [ 0.,  0.,  1.,  0.,  0.]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_of_rfe = rfe_factory.fit_transform(analytic_df, y)\n",
    "results_of_rfe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Shows three model scores. KBest, rfe, and logistic regression on the dataframe. The models were run on the full dataset and there is probably some overfitting. Can retest models on train/test data. Not sure whether to further pursue kbest and rfe for this dataset or just switch over to gridsearch..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.81032547699214363"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_kbest_all_columns = LogisticRegression()\n",
    "model_kbest_all_columns.fit(results_kbest_all, y)\n",
    "model_kbest_all_columns.score(results_kbest_all, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.78900112233445563"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_for_rfe_columns = LogisticRegression()\n",
    "model_for_rfe_columns.fit(results_of_rfe, y)\n",
    "model_for_rfe_columns.score(results_of_rfe, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.81032547699214363"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_df = LogisticRegression()\n",
    "full_df.fit(analytic_df.as_matrix(), y)\n",
    "full_df.score(analytic_df.as_matrix(), y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like my kbest and entire df have same results. Should go back and restrict k='all'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SelectKBest(k=4, score_func=<function f_classif at 0x117722b90>)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lets redo a kbest on train data with restricted columns\n",
    "kbest = SelectKBest(k=4)\n",
    "kbest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  1.,  1.,  0.],\n",
       "       [ 1.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  1.,  0.],\n",
       "       ..., \n",
       "       [ 0.,  0.,  1.,  0.],\n",
       "       [ 1.,  1.,  0.,  0.],\n",
       "       [ 0.,  1.,  0.,  0.]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_of_kbest4 = kbest.fit_transform(analytic_df, y)\n",
    "results_of_kbest4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  7.91364033e+01,   7.81480472e+00,   3.72405724e+02,\n",
       "         4.35351609e+00,   1.11057220e+00,   5.96346384e+00,\n",
       "         3.22216280e+00,   1.18463440e-02,   2.20754686e+01,\n",
       "         1.13176268e+01,   4.67733759e-01])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kbest.scores_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.79012345679012341"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# showing a lower score with less variables\n",
    "model_for_kbest4_columns = LogisticRegression()\n",
    "model_for_kbest4_columns.fit(results_of_kbest4, y)\n",
    "model_for_kbest4_columns.score(results_of_kbest4, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, moving back to logistic regression for now. Then will run it through a grid search. Going to do these models on train data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((668, 4), (668,))"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pclass=1</th>\n",
       "      <th>pclass=2</th>\n",
       "      <th>Sex_male</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Embarked_Missing</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Embarked_S</th>\n",
       "      <th>Child</th>\n",
       "      <th>Old Person</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pclass=1  pclass=2  Sex_male   Age  SibSp  Parch  Embarked_Missing  \\\n",
       "0       0.0       0.0       1.0  22.0      1      0               0.0   \n",
       "1       1.0       0.0       0.0  38.0      1      0               0.0   \n",
       "2       0.0       0.0       0.0  26.0      0      0               0.0   \n",
       "3       1.0       0.0       0.0  35.0      1      0               0.0   \n",
       "4       0.0       0.0       1.0  35.0      0      0               0.0   \n",
       "\n",
       "   Embarked_Q  Embarked_S  Child  Old Person  \n",
       "0         0.0         1.0      0           0  \n",
       "1         0.0         0.0      0           0  \n",
       "2         0.0         1.0      0           0  \n",
       "3         0.0         1.0      0           0  \n",
       "4         0.0         1.0      0           0  "
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analytic_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pclass=1</th>\n",
       "      <th>Sex_male</th>\n",
       "      <th>Old Person</th>\n",
       "      <th>Embarked_Missing</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>404</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>572</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>718</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>453</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>441</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     pclass=1  Sex_male  Old Person  Embarked_Missing\n",
       "404       0.0       0.0           0               0.0\n",
       "572       1.0       1.0           0               0.0\n",
       "718       0.0       1.0           0               0.0\n",
       "453       1.0       1.0           0               0.0\n",
       "441       0.0       1.0           0               0.0"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([u'pclass=1', u'Sex_male', u'Old Person', u'Embarked_Missing'], dtype='object')"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this is now wrong since I re-ran it. Need to open a new notebook and start over\n",
    "x_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "messy_model_analytic = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.81736526946107779"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messy_model_analytic.fit(x_train, y_train)\n",
    "messy_model_analytic.score(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "X has 4 features per sample; expecting 21",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-123-739e515c56dc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmess_predictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmessy_model_analytic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mmess_predictions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Driz/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/base.pyc\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    266\u001b[0m             \u001b[0mPredicted\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0mper\u001b[0m \u001b[0msample\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m         \"\"\"\n\u001b[0;32m--> 268\u001b[0;31m         \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecision_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    269\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m             \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Driz/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/base.pyc\u001b[0m in \u001b[0;36mdecision_function\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    247\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mn_features\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    248\u001b[0m             raise ValueError(\"X has %d features per sample; expecting %d\"\n\u001b[0;32m--> 249\u001b[0;31m                              % (X.shape[1], n_features))\n\u001b[0m\u001b[1;32m    250\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    251\u001b[0m         scores = safe_sparse_dot(X, self.coef_.T,\n",
      "\u001b[0;31mValueError\u001b[0m: X has 4 features per sample; expecting 21"
     ]
    }
   ],
   "source": [
    "mess_predictions = messy_model_analytic.predict(x_train)\n",
    "mess_predictions[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mess_predict_proba = messy_model_analytic.predict_proba(x_train)\n",
    "mess_predict_proba[0:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "confusion_matrix(y_train, mess_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print classification_report(y_train, mess_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sns.heatmap(confusion_matrix(y_train, mess_predictions), annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That is a pretty good score. It also contains quite a lot of columns. Could it be overfit? Should I move into a grid search before running my model on my test data. Also, I may pluck some x variables out for fun and see how it alters my score. Also, need confusion matrix at some point. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "xs = x_train[['Sex_female', 'Age', 'Embarked_Q', \n",
    "             'Cabin_F','Pclass']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "paired_down_model = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.79640718562874246"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# not as good of a score with my plucked x variables (but still decent)\n",
    "paired_down_model.fit(xs, y_train)\n",
    "paired_down_model.score(xs, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 1, 0])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = paired_down_model.predict(xs)\n",
    "predictions[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.80302019,  0.19697981],\n",
       "       [ 0.93043005,  0.06956995],\n",
       "       [ 0.84992995,  0.15007005],\n",
       "       [ 0.36695183,  0.63304817],\n",
       "       [ 0.88388061,  0.11611939]])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_proba = paired_down_model.predict_proba(xs)\n",
    "predict_proba[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sex_female</th>\n",
       "      <th>Age</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Cabin_F</th>\n",
       "      <th>Pclass</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>278</th>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Sex_female  Age  Embarked_Q  Cabin_F  Pclass\n",
       "278         0.0  7.0         1.0      0.0       3"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xs.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The predict_proba shows the probability each variable points to whether or not someone survived. First column predicts the variables possible association to death and second life."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Going to do a confusion matrix now to check for accuracy and evaluate model fit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predicted_dead</th>\n",
       "      <th>predicted_alive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>is_dead</th>\n",
       "      <td>356</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is_alive</th>\n",
       "      <td>78</td>\n",
       "      <td>176</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          predicted_dead  predicted_alive\n",
       "is_dead              356               58\n",
       "is_alive              78              176"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confuse_matrix_1 = np.array(confusion_matrix(y_train, predictions))\n",
    "\n",
    "confusion = pd.DataFrame(confuse_matrix_1, index=['is_dead', 'is_alive'],\n",
    "                         columns=['predicted_dead', 'predicted_alive'])\n",
    "\n",
    "confusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The confusion matrix above details the predictions of my model. Its shows that it correctly predicted 356 correctly dead and 176 alive. It returned 78 false positives and 58 false negatives. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's plot the ROC curve to get a visual representation of the confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([ 0.        ,  0.00241546,  0.00241546,  0.00241546,  0.00241546,\n",
      "        0.00241546,  0.00241546,  0.00241546,  0.00241546,  0.00241546,\n",
      "        0.00241546,  0.00241546,  0.00241546,  0.00241546,  0.00241546,\n",
      "        0.00241546,  0.00241546,  0.00241546,  0.00241546,  0.00241546,\n",
      "        0.00241546,  0.00241546,  0.00241546,  0.00241546,  0.00241546,\n",
      "        0.00241546,  0.00241546,  0.00241546,  0.00241546,  0.00241546,\n",
      "        0.00483092,  0.00483092,  0.00483092,  0.00483092,  0.00483092,\n",
      "        0.00483092,  0.00724638,  0.00724638,  0.00724638,  0.00724638,\n",
      "        0.01207729,  0.01207729,  0.01449275,  0.01449275,  0.01690821,\n",
      "        0.01690821,  0.01690821,  0.01932367,  0.01932367,  0.02415459,\n",
      "        0.03381643,  0.03381643,  0.03623188,  0.03623188,  0.0410628 ,\n",
      "        0.0410628 ,  0.04589372,  0.04589372,  0.04589372,  0.04830918,\n",
      "        0.05072464,  0.0531401 ,  0.05797101,  0.05797101,  0.06280193,\n",
      "        0.07246377,  0.07487923,  0.07971014,  0.08454106,  0.08695652,\n",
      "        0.08695652,  0.08695652,  0.08695652,  0.08937198,  0.08937198,\n",
      "        0.0942029 ,  0.09903382,  0.10144928,  0.12801932,  0.12801932,\n",
      "        0.13043478,  0.13043478,  0.1352657 ,  0.14009662,  0.14975845,\n",
      "        0.14975845,  0.15458937,  0.15458937,  0.16183575,  0.19806763,\n",
      "        0.20048309,  0.20289855,  0.20289855,  0.20531401,  0.20531401,\n",
      "        0.20531401,  0.21014493,  0.21980676,  0.22222222,  0.22463768,\n",
      "        0.22463768,  0.2294686 ,  0.23188406,  0.23671498,  0.23913043,\n",
      "        0.24879227,  0.24879227,  0.24879227,  0.25120773,  0.25603865,\n",
      "        0.25845411,  0.26086957,  0.26570048,  0.26811594,  0.27294686,\n",
      "        0.27777778,  0.28743961,  0.29227053,  0.29951691,  0.30193237,\n",
      "        0.30917874,  0.31400966,  0.31642512,  0.32608696,  0.33091787,\n",
      "        0.33333333,  0.34057971,  0.34541063,  0.352657  ,  0.35748792,\n",
      "        0.35990338,  0.3647343 ,  0.37439614,  0.37681159,  0.38647343,\n",
      "        0.38888889,  0.39613527,  0.40096618,  0.40338164,  0.41062802,\n",
      "        0.42270531,  0.43236715,  0.44202899,  0.44202899,  0.4468599 ,\n",
      "        0.44927536,  0.44927536,  0.45169082,  0.45652174,  0.46376812,\n",
      "        0.46859903,  0.48309179,  0.49758454,  0.50241546,  0.51690821,\n",
      "        0.52898551,  0.53864734,  0.55555556,  0.55555556,  0.57246377,\n",
      "        0.57487923,  0.61835749,  0.62077295,  0.64009662,  0.64251208,\n",
      "        0.66183575,  0.66425121,  0.6763285 ,  0.67874396,  0.6884058 ,\n",
      "        0.70289855,  0.70531401,  0.71014493,  0.72705314,  0.73188406,\n",
      "        0.74396135,  0.85748792,  0.87439614,  0.88405797,  0.88405797,\n",
      "        0.88888889,  0.90338164,  0.91304348,  0.92512077,  0.93478261,\n",
      "        0.93719807,  0.94202899,  0.94927536,  0.95410628,  0.96135266,\n",
      "        0.96376812,  0.96859903,  0.97101449,  0.97584541,  0.98067633,\n",
      "        0.98550725,  1.        ]), array([ 0.        ,  0.        ,  0.01181102,  0.02362205,  0.03937008,\n",
      "        0.04330709,  0.0511811 ,  0.06299213,  0.07086614,  0.09055118,\n",
      "        0.0984252 ,  0.11811024,  0.13385827,  0.14173228,  0.1496063 ,\n",
      "        0.16535433,  0.17322835,  0.18110236,  0.18897638,  0.21259843,\n",
      "        0.22047244,  0.2480315 ,  0.25590551,  0.27952756,  0.31102362,\n",
      "        0.32677165,  0.33464567,  0.34251969,  0.35433071,  0.35826772,\n",
      "        0.36614173,  0.38188976,  0.38976378,  0.4015748 ,  0.40551181,\n",
      "        0.41732283,  0.41732283,  0.42125984,  0.43307087,  0.44094488,\n",
      "        0.44488189,  0.45275591,  0.45275591,  0.46062992,  0.46062992,\n",
      "        0.46850394,  0.47244094,  0.47244094,  0.47637795,  0.47637795,\n",
      "        0.47637795,  0.48031496,  0.48031496,  0.49212598,  0.49212598,\n",
      "        0.5       ,  0.5       ,  0.50787402,  0.51181102,  0.51181102,\n",
      "        0.51574803,  0.51574803,  0.52755906,  0.53149606,  0.53149606,\n",
      "        0.59448819,  0.59448819,  0.5984252 ,  0.60629921,  0.60629921,\n",
      "        0.61023622,  0.62204724,  0.62598425,  0.63385827,  0.64566929,\n",
      "        0.64566929,  0.6496063 ,  0.6496063 ,  0.66535433,  0.66929134,\n",
      "        0.67322835,  0.69291339,  0.69291339,  0.69291339,  0.69291339,\n",
      "        0.69685039,  0.69685039,  0.70472441,  0.70472441,  0.71259843,\n",
      "        0.71259843,  0.71653543,  0.72047244,  0.72047244,  0.72440945,\n",
      "        0.73622047,  0.7480315 ,  0.75590551,  0.75590551,  0.75984252,\n",
      "        0.77559055,  0.77952756,  0.77952756,  0.77952756,  0.77952756,\n",
      "        0.77952756,  0.78346457,  0.79527559,  0.7992126 ,  0.80314961,\n",
      "        0.80708661,  0.80708661,  0.80708661,  0.80708661,  0.80708661,\n",
      "        0.81102362,  0.81102362,  0.81102362,  0.81496063,  0.81496063,\n",
      "        0.81496063,  0.81496063,  0.81496063,  0.81496063,  0.81496063,\n",
      "        0.81496063,  0.81496063,  0.81496063,  0.81496063,  0.81496063,\n",
      "        0.81496063,  0.81496063,  0.82283465,  0.82283465,  0.82283465,\n",
      "        0.82283465,  0.82677165,  0.82677165,  0.83070866,  0.83070866,\n",
      "        0.83464567,  0.83464567,  0.83464567,  0.84645669,  0.84645669,\n",
      "        0.8503937 ,  0.85826772,  0.85826772,  0.86220472,  0.86220472,\n",
      "        0.86614173,  0.86614173,  0.86614173,  0.86614173,  0.86614173,\n",
      "        0.86614173,  0.87007874,  0.87401575,  0.87795276,  0.88582677,\n",
      "        0.88582677,  0.89370079,  0.89370079,  0.89370079,  0.89370079,\n",
      "        0.8976378 ,  0.8976378 ,  0.9015748 ,  0.9015748 ,  0.90551181,\n",
      "        0.91338583,  0.91338583,  0.92519685,  0.92519685,  0.92519685,\n",
      "        0.93307087,  0.96062992,  0.96456693,  0.96456693,  0.96850394,\n",
      "        0.98818898,  0.98818898,  0.98818898,  0.98818898,  0.98818898,\n",
      "        0.98818898,  0.99212598,  0.99212598,  0.99212598,  0.99212598,\n",
      "        0.99212598,  1.        ,  1.        ,  1.        ,  1.        ,\n",
      "        1.        ,  1.        ]), array([ 3.79894723,  2.79894723,  2.49365791,  2.47017411,  2.42320653,\n",
      "        2.39972273,  2.35275515,  2.32927135,  2.29614958,  2.28230376,\n",
      "        2.16488479,  2.14846686,  2.141401  ,  2.11791721,  2.05636934,\n",
      "        2.02398203,  2.00049824,  1.93895037,  1.93004686,  1.81303434,\n",
      "        1.81262789,  1.71869271,  1.69520892,  1.53082236,  1.46077743,\n",
      "        1.41380984,  1.39032605,  1.3664358 ,  1.34335846,  1.31987467,\n",
      "        1.27290708,  1.15548811,  1.13200432,  1.10852052,  1.08503673,\n",
      "        1.06155294,  1.01458535,  0.98358713,  0.96761776,  0.94454042,\n",
      "        0.92105662,  0.92065017,  0.89757283,  0.87408904,  0.87368259,\n",
      "        0.85060524,  0.85019879,  0.82712145,  0.81748347,  0.77051589,\n",
      "        0.75667007,  0.74703209,  0.73318627,  0.73277982,  0.70006451,\n",
      "        0.66273489,  0.6275092 ,  0.6157673 ,  0.61536085,  0.59228351,\n",
      "        0.56879972,  0.56839327,  0.54531592,  0.52183213,  0.49834834,\n",
      "        0.49577622,  0.47696846,  0.47486454,  0.45138075,  0.44174277,\n",
      "        0.42789695,  0.40441316,  0.39019348,  0.35744557,  0.33396178,\n",
      "        0.31047798,  0.28699419,  0.27735622,  0.27057626,  0.2635104 ,\n",
      "        0.2400266 ,  0.11541276,  0.05215625,  0.00518866, -0.0813611 ,\n",
      "       -0.12832869, -0.15919789, -0.19878007, -0.26923145, -0.28564939,\n",
      "       -0.29271525, -0.31619904, -0.33968283, -0.36316663, -0.38665042,\n",
      "       -0.41013421, -0.43361801, -0.4805856 , -0.50406939, -0.52755318,\n",
      "       -0.57452077, -0.64497215, -0.65671405, -0.66845595, -0.67129433,\n",
      "       -0.69193974, -0.71501708, -0.71542353, -0.73890733, -0.76239112,\n",
      "       -0.78587492, -0.80935871, -0.8563263 , -0.87981009, -0.90288743,\n",
      "       -0.90329389, -0.94985502, -0.95026147, -0.97333882, -0.99722906,\n",
      "       -1.0203064 , -1.02071285, -1.04419665, -1.06727399, -1.09075778,\n",
      "       -1.09116424, -1.11424158, -1.13772537, -1.16120917, -1.18469296,\n",
      "       -1.19927324, -1.20817675, -1.22459469, -1.22532915, -1.23166055,\n",
      "       -1.232067  , -1.25514434, -1.25555079, -1.27862814, -1.30211193,\n",
      "       -1.32559572, -1.37256331, -1.44301469, -1.48957583, -1.51305962,\n",
      "       -1.51346607, -1.53654342, -1.53694987, -1.56002721, -1.65436884,\n",
      "       -1.67744618, -1.73405174, -1.7952716 , -1.82798692, -1.84183274,\n",
      "       -1.86531653, -1.88880032, -1.91228412, -1.92192209, -1.93576791,\n",
      "       -1.93617436, -1.93834003, -1.94750981, -1.9592517 , -1.96888968,\n",
      "       -1.9827355 , -1.99237347, -2.02970309, -2.04144498, -2.05318688,\n",
      "       -2.07667067, -2.07707713, -2.10015447, -2.12363826, -2.13538016,\n",
      "       -2.14712206, -2.16353999, -2.17060585, -2.19198572, -2.19408964,\n",
      "       -2.21757344, -2.24105723, -2.26454102, -2.28802482, -2.31150861,\n",
      "       -2.33499241, -2.38195999, -2.40544379, -2.42892758, -2.45241138,\n",
      "       -2.47589517, -2.52286276, -2.53460465, -2.56983034, -2.64028173,\n",
      "       -2.66376552, -3.20389278]))\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAqcAAAI+CAYAAACBjKOPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11ae0e390>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_score = paired_down_model.decision_function(xs)\n",
    "\n",
    "FPR = dict()\n",
    "TPR = dict()\n",
    "ROC_AUC = dict() # {}\n",
    "\n",
    "# For class 1, find the area under the curve\n",
    "\n",
    "print roc_curve(y_train, y_score)\n",
    "\n",
    "FPR[1], TPR[1], _ = roc_curve(y_train, y_score)\n",
    "ROC_AUC[1] = auc(FPR[1], TPR[1])\n",
    "\n",
    "\n",
    "# Plot of a ROC curve for class 1 (Survival)\n",
    "plt.figure(figsize=[11,9])\n",
    "plt.plot(FPR[1], TPR[1], label='ROC curve (area = %0.2f)' % ROC_AUC[1], linewidth=4)\n",
    "plt.plot([0, 1], [0, 1], 'k--', linewidth=4)\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate', fontsize=18)\n",
    "plt.ylabel('True Positive Rate', fontsize=18)\n",
    "plt.title('Variables Predicting Survival', fontsize=18)\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The greater the area under the curve shows the higher the ratio of true positives to false positives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.79640718562874246"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc = accuracy_score(y_train, predictions)\n",
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.82      0.86      0.84       414\n",
      "          1       0.75      0.69      0.72       254\n",
      "\n",
      "avg / total       0.79      0.80      0.79       668\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_train, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even though I have higher scoring models than this one I am going to go ahead and run it on my test data just for practice."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The 0 and 1 on the left column indicate the two classes predicted by the model. For models with multiple classes there would be more rows and labels.\n",
    "\n",
    "Each of the columns indicate an important metric for evaluating classification model performance.\n",
    "\n",
    "Precision is the ability of the classifier to avoid mislabeling when the observation belongs in another class.\n",
    "\n",
    "Precision = True Positives / (True Positives + False Positives)\n",
    "\n",
    "A precision score of 1 indicates that the classifier never mistakenly added observations from another class. A precision score of 0 would mean that the classifier misclassified every instance of the current class.\n",
    "\n",
    "recall is the ability of the classifier to correctly identify all observations in the current class.\n",
    "\n",
    "Recall = True Positives / (True Positives + False Negatives)\n",
    "\n",
    "A recall score of 1 indicates that the classifier correctly predicted (found) all observations of the current class (by implication, no false negatives, or misclassifications of the current class). A recall score of 0 alternatively means that the classifier missed all observations of the current class.\n",
    "\n",
    "f1-score is the harmonic mean of the precision and recall. The harmonic mean is used here rather than the more conventional arithmetic mean because the harmonic mean is more appropriate for averaging rates.\n",
    "\n",
    "F1-Score = 2 * (Precision * Recall) / (Precision + Recall)\n",
    "\n",
    "The f1-score's best value is 1 and worst value is 0, like the precision and recall scores. It is a useful metric for taking into account both measures at once.\n",
    "\n",
    "support is simply the number of observations of the labelled class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "xs_test = x_test[['Sex_female', 'Age', 'Embarked_Q', \n",
    "             'Cabin_F','Pclass']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using paired_down_model with test data we get: 0.811659192825\n"
     ]
    }
   ],
   "source": [
    "print 'Using paired_down_model with test data we get:', paired_down_model.score(xs_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0.79640718562874246 <-- was score from train data. When compared to test data, test data did have a higher score. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's not surprising that 'Sex_female', 'Age', and 'Pclass' variables did well in identifying whether or not a passenger survived. Through historical records we know that women, children, and first class passengers where given priority when boarding life boats."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will do a grid search on the train data to see what kind of scores return."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "parameters = {\n",
    "    'penalty': ['l1', 'l2'],\n",
    "    'C': [0.1, 1, 10, 5, .001]\n",
    "}\n",
    "paired_down_model = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=6, error_score='raise',\n",
       "       estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False),\n",
       "       fit_params={}, iid=True, n_jobs=1,\n",
       "       param_grid={'penalty': ['l1', 'l2'], 'C': [0.1, 1, 10, 5, 0.001]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, scoring=None, verbose=10)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search = GridSearchCV(estimator=paired_down_model,\n",
    "                          param_grid=parameters,\n",
    "                          verbose=10,\n",
    "                          cv=6)\n",
    "grid_search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 6 folds for each of 10 candidates, totalling 60 fits\n",
      "[CV] penalty=l1, C=0.1 ...............................................\n",
      "[CV] ...................... penalty=l1, C=0.1, score=0.767857 -   0.0s\n",
      "[CV] penalty=l1, C=0.1 ...............................................\n",
      "[CV] ...................... penalty=l1, C=0.1, score=0.803571 -   0.0s\n",
      "[CV] penalty=l1, C=0.1 ...............................................\n",
      "[CV] ...................... penalty=l1, C=0.1, score=0.747748 -   0.0s\n",
      "[CV] penalty=l1, C=0.1 ...............................................\n",
      "[CV] ...................... penalty=l1, C=0.1, score=0.819820 -   0.0s\n",
      "[CV] penalty=l1, C=0.1 ...............................................\n",
      "[CV] ...................... penalty=l1, C=0.1, score=0.756757 -   0.0s\n",
      "[CV] penalty=l1, C=0.1 ...............................................\n",
      "[CV] ...................... penalty=l1, C=0.1, score=0.828829 -   0.0s\n",
      "[CV] penalty=l2, C=0.1 ...............................................\n",
      "[CV] ...................... penalty=l2, C=0.1, score=0.776786 -   0.0s\n",
      "[CV] penalty=l2, C=0.1 ...............................................\n",
      "[CV] ...................... penalty=l2, C=0.1, score=0.812500 -   0.0s\n",
      "[CV] penalty=l2, C=0.1 ...............................................\n",
      "[CV] ...................... penalty=l2, C=0.1, score=0.747748 -   0.0s\n",
      "[CV] penalty=l2, C=0.1 ...............................................\n",
      "[CV] ...................... penalty=l2, C=0.1, score=0.828829 -   0.0s\n",
      "[CV] penalty=l2, C=0.1 ...............................................\n",
      "[CV] ...................... penalty=l2, C=0.1, score=0.756757 -   0.0s\n",
      "[CV] penalty=l2, C=0.1 ...............................................\n",
      "[CV] ...................... penalty=l2, C=0.1, score=0.828829 -   0.0s\n",
      "[CV] penalty=l1, C=1 .................................................\n",
      "[CV] ........................ penalty=l1, C=1, score=0.776786 -   0.0s\n",
      "[CV] penalty=l1, C=1 .................................................\n",
      "[CV] ........................ penalty=l1, C=1, score=0.803571 -   0.0s\n",
      "[CV] penalty=l1, C=1 .................................................\n",
      "[CV] ........................ penalty=l1, C=1, score=0.756757 -   0.0s\n",
      "[CV] penalty=l1, C=1 .................................................\n",
      "[CV] ........................ penalty=l1, C=1, score=0.810811 -   0.0s\n",
      "[CV] penalty=l1, C=1 .................................................\n",
      "[CV] ........................ penalty=l1, C=1, score=0.756757 -   0.0s\n",
      "[CV] penalty=l1, C=1 .................................................\n",
      "[CV] ........................ penalty=l1, C=1, score=0.828829 -   0.0s\n",
      "[CV] penalty=l2, C=1 .................................................\n",
      "[CV] ........................ penalty=l2, C=1, score=0.776786 -   0.0s\n",
      "[CV] penalty=l2, C=1 .................................................\n",
      "[CV] ........................ penalty=l2, C=1, score=0.812500 -   0.0s\n",
      "[CV] penalty=l2, C=1 .................................................\n",
      "[CV] ........................ penalty=l2, C=1, score=0.756757 -   0.0s\n",
      "[CV] penalty=l2, C=1 .................................................\n",
      "[CV] ........................ penalty=l2, C=1, score=0.828829 -   0.0s\n",
      "[CV] penalty=l2, C=1 .................................................\n",
      "[CV] ........................ penalty=l2, C=1, score=0.756757 -   0.0s\n",
      "[CV] penalty=l2, C=1 .................................................\n",
      "[CV] ........................ penalty=l2, C=1, score=0.828829 -   0.0s\n",
      "[CV] penalty=l1, C=10 ................................................\n",
      "[CV] ....................... penalty=l1, C=10, score=0.776786 -   0.0s\n",
      "[CV] penalty=l1, C=10 ................................................\n",
      "[CV] ....................... penalty=l1, C=10, score=0.821429 -   0.0s\n",
      "[CV] penalty=l1, C=10 ................................................\n",
      "[CV] ....................... penalty=l1, C=10, score=0.756757 -   0.0s\n",
      "[CV] penalty=l1, C=10 ................................................\n",
      "[CV] ....................... penalty=l1, C=10, score=0.819820 -   0.0s\n",
      "[CV] penalty=l1, C=10 ................................................\n",
      "[CV] ....................... penalty=l1, C=10, score=0.756757 -   0.0s\n",
      "[CV] penalty=l1, C=10 ................................................\n",
      "[CV] ....................... penalty=l1, C=10, score=0.828829 -   0.0s\n",
      "[CV] penalty=l2, C=10 ................................................\n",
      "[CV] ....................... penalty=l2, C=10, score=0.785714 -   0.0s\n",
      "[CV] penalty=l2, C=10 ................................................\n",
      "[CV] ....................... penalty=l2, C=10, score=0.821429 -   0.0s\n",
      "[CV] penalty=l2, C=10 ................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 tasks       | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 tasks       | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 tasks       | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  12 tasks       | elapsed:    0.1s\n",
      "[Parallel(n_jobs=1)]: Done  17 tasks       | elapsed:    0.1s\n",
      "[Parallel(n_jobs=1)]: Done  24 tasks       | elapsed:    0.2s\n",
      "[Parallel(n_jobs=1)]: Done  31 tasks       | elapsed:    0.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ....................... penalty=l2, C=10, score=0.765766 -   0.0s\n",
      "[CV] penalty=l2, C=10 ................................................\n",
      "[CV] ....................... penalty=l2, C=10, score=0.819820 -   0.0s\n",
      "[CV] penalty=l2, C=10 ................................................\n",
      "[CV] ....................... penalty=l2, C=10, score=0.756757 -   0.0s\n",
      "[CV] penalty=l2, C=10 ................................................\n",
      "[CV] ....................... penalty=l2, C=10, score=0.828829 -   0.0s\n",
      "[CV] penalty=l1, C=5 .................................................\n",
      "[CV] ........................ penalty=l1, C=5, score=0.776786 -   0.0s\n",
      "[CV] penalty=l1, C=5 .................................................\n",
      "[CV] ........................ penalty=l1, C=5, score=0.821429 -   0.0s\n",
      "[CV] penalty=l1, C=5 .................................................\n",
      "[CV] ........................ penalty=l1, C=5, score=0.765766 -   0.0s\n",
      "[CV] penalty=l1, C=5 .................................................\n",
      "[CV] ........................ penalty=l1, C=5, score=0.819820 -   0.0s\n",
      "[CV] penalty=l1, C=5 .................................................\n",
      "[CV] ........................ penalty=l1, C=5, score=0.756757 -   0.0s\n",
      "[CV] penalty=l1, C=5 .................................................\n",
      "[CV] ........................ penalty=l1, C=5, score=0.828829 -   0.0s\n",
      "[CV] penalty=l2, C=5 .................................................\n",
      "[CV] ........................ penalty=l2, C=5, score=0.776786 -   0.0s\n",
      "[CV] penalty=l2, C=5 .................................................\n",
      "[CV] ........................ penalty=l2, C=5, score=0.821429 -   0.0s\n",
      "[CV] penalty=l2, C=5 .................................................\n",
      "[CV] ........................ penalty=l2, C=5, score=0.765766 -   0.0s\n",
      "[CV] penalty=l2, C=5 .................................................\n",
      "[CV] ........................ penalty=l2, C=5, score=0.819820 -   0.0s\n",
      "[CV] penalty=l2, C=5 .................................................\n",
      "[CV] ........................ penalty=l2, C=5, score=0.756757 -   0.0s\n",
      "[CV] penalty=l2, C=5 .................................................\n",
      "[CV] ........................ penalty=l2, C=5, score=0.828829 -   0.0s\n",
      "[CV] penalty=l1, C=0.001 .............................................\n",
      "[CV] .................... penalty=l1, C=0.001, score=0.616071 -   0.0s\n",
      "[CV] penalty=l1, C=0.001 .............................................\n",
      "[CV] .................... penalty=l1, C=0.001, score=0.616071 -   0.0s\n",
      "[CV] penalty=l1, C=0.001 .............................................\n",
      "[CV] .................... penalty=l1, C=0.001, score=0.621622 -   0.0s\n",
      "[CV] penalty=l1, C=0.001 .............................................\n",
      "[CV] .................... penalty=l1, C=0.001, score=0.621622 -   0.0s\n",
      "[CV] penalty=l1, C=0.001 .............................................\n",
      "[CV] .................... penalty=l1, C=0.001, score=0.621622 -   0.0s\n",
      "[CV] penalty=l1, C=0.001 .............................................\n",
      "[CV] .................... penalty=l1, C=0.001, score=0.621622 -   0.0s\n",
      "[CV] penalty=l2, C=0.001 .............................................\n",
      "[CV] .................... penalty=l2, C=0.001, score=0.616071 -   0.0s\n",
      "[CV] penalty=l2, C=0.001 .............................................\n",
      "[CV] .................... penalty=l2, C=0.001, score=0.616071 -   0.0s\n",
      "[CV] penalty=l2, C=0.001 .............................................\n",
      "[CV] .................... penalty=l2, C=0.001, score=0.621622 -   0.0s\n",
      "[CV] penalty=l2, C=0.001 .............................................\n",
      "[CV] .................... penalty=l2, C=0.001, score=0.621622 -   0.0s\n",
      "[CV] penalty=l2, C=0.001 .............................................\n",
      "[CV] .................... penalty=l2, C=0.001, score=0.621622 -   0.0s\n",
      "[CV] penalty=l2, C=0.001 .............................................\n",
      "[CV] .................... penalty=l2, C=0.001, score=0.621622 -   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  40 tasks       | elapsed:    0.3s\n",
      "[Parallel(n_jobs=1)]: Done  49 tasks       | elapsed:    0.3s\n",
      "[Parallel(n_jobs=1)]: Done  60 tasks       | elapsed:    0.4s\n",
      "[Parallel(n_jobs=1)]: Done  60 out of  60 | elapsed:    0.4s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=6, error_score='raise',\n",
       "       estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False),\n",
       "       fit_params={}, iid=True, n_jobs=1,\n",
       "       param_grid={'penalty': ['l1', 'l2'], 'C': [0.1, 1, 10, 5, 0.001]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, scoring=None, verbose=10)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.fit(xs, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.79640718562874246"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=10, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=10, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_estimator_.fit(xs, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.79491017964071853"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_estimator_.score(xs, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictors = grid_search.best_estimator_.predict(xs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[260, 151],\n",
       "       [173,  84]])"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_train, predictors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predicted_dead</th>\n",
       "      <th>predicted_alive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>is_dead</th>\n",
       "      <td>262</td>\n",
       "      <td>149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is_alive</th>\n",
       "      <td>172</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          predicted_dead  predicted_alive\n",
       "is_dead              262              149\n",
       "is_alive             172               85"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confuse_matrix_1 = np.array(confusion_matrix(y_train, predictions))\n",
    "\n",
    "confusion = pd.DataFrame(confuse_matrix_1, index=['is_dead', 'is_alive'],\n",
    "                         columns=['predicted_dead', 'predicted_alive'])\n",
    "\n",
    "confusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.82      0.86      0.84       414\n",
      "          1       0.75      0.69      0.72       254\n",
      "\n",
      "avg / total       0.79      0.79      0.79       668\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print classification_report(y_train, predictors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x11b088910>"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAV4AAAD9CAYAAAD01B/uAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x117bb30d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.heatmap(confusion_matrix(y_train, predictors), annot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Before I accept this model I want to go back and restrain my x variables to be old age, male, first class, and missing embarked location."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pclass=1</th>\n",
       "      <th>pclass=2</th>\n",
       "      <th>Sex_male</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Embarked_Missing</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Embarked_S</th>\n",
       "      <th>Child</th>\n",
       "      <th>Old Person</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pclass=1  pclass=2  Sex_male   Age  SibSp  Parch  Embarked_Missing  \\\n",
       "0       0.0       0.0       1.0  22.0      1      0               0.0   \n",
       "\n",
       "   Embarked_Q  Embarked_S  Child  Old Person  \n",
       "0         0.0         1.0      0           0  "
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analytic_df.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Need to make a train test split on this dataframe. Then I will run a logistic regression on my plucked out x variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_plucked = analytic_df[['pclass=1', 'Sex_male', 'Old Person', 'Embarked_Missing']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(data_plucked, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((668, 4), (668,))"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((223, 4), (223,))"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pluck_model = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pluck_model.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.78892215568862278"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pluck_model.score(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pluck_model_lasso = LogisticRegression(penalty='l1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.78892215568862278"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pluck_model_lasso.fit(x_train, y_train)\n",
    "pluck_model_lasso.score(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict = pluck_model.predict(x_train)\n",
    "predict[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.32264311,  0.67735689],\n",
       "       [ 0.59633327,  0.40366673],\n",
       "       [ 0.85520737,  0.14479263],\n",
       "       ..., \n",
       "       [ 0.32264311,  0.67735689],\n",
       "       [ 0.85520737,  0.14479263],\n",
       "       [ 0.32264311,  0.67735689]])"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_proba = pluck_model.predict_proba(x_train)\n",
    "predict_proba[0:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before modeling on my test data, let's do a confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[352,  59],\n",
       "       [ 82, 175]])"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_train, predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predicted_dead</th>\n",
       "      <th>predicted_alive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>is_dead</th>\n",
       "      <td>352</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is_alive</th>\n",
       "      <td>82</td>\n",
       "      <td>175</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          predicted_dead  predicted_alive\n",
       "is_dead              352               59\n",
       "is_alive              82              175"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confuse_matrix_org = np.array(confusion_matrix(y_train, predict))\n",
    "\n",
    "confusion_org = pd.DataFrame(confuse_matrix_org, index=['is_dead', 'is_alive'],\n",
    "                         columns=['predicted_dead', 'predicted_alive'])\n",
    "\n",
    "confusion_org"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above confusion matrix shows that there were 352 true negatives predicted by the model, 59 false negatives, 82 false positives, and 175 true positives. So, predicting that 59 people survived when they were in fact dead is not too shabby for my model. Let's check precision with a classification report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.81      0.86      0.83       411\n",
      "          1       0.75      0.68      0.71       257\n",
      "\n",
      "avg / total       0.79      0.79      0.79       668\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print classification_report(y_train, predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overall good scores for predicting death. On the other hand it may not be the best model if you are a glass half full kind of person."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x11ae31890>"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAV4AAAD9CAYAAAD01B/uAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nM3glKWUGrySl7H8AKsj1M1ykrKgAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11ae31650>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.heatmap(confusion_matrix(y_train,predict), annot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's run test data through this model now and see what happens to the scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.78026905829596416"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pluck_model.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After passing the test data through the model it shows a lower score. This may point to some overfitting of the data. Will go back up and re-evaluate some of my earlier models to make sure I ran them all on train-test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusion:\n",
    "\n",
    "So, let's recap: I have made three different models. All vary in their predictive power. Best score has been with messy_model_analytic (0.817 on train and ___ on test___). Blah, blah, blah--write more here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
